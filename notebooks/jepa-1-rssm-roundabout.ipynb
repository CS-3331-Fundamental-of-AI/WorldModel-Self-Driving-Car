{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf111d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:21:21.360207Z",
     "iopub.status.busy": "2026-01-02T05:21:21.359835Z",
     "iopub.status.idle": "2026-01-02T05:21:34.392460Z",
     "shell.execute_reply": "2026-01-02T05:21:34.391745Z"
    },
    "papermill": {
     "duration": 13.044701,
     "end_time": "2026-01-02T05:21:34.394176",
     "exception": false,
     "start_time": "2026-01-02T05:21:21.349475",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\r\n",
      "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\r\n",
      "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torchcodec\r\n",
      "Successfully installed torchcodec-0.9.1\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.10.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\r\n",
      "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.7.0\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.1/952.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "stable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.2.3 which is incompatible.\r\n",
      "kaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.2.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec\n",
    "!pip install torch-geometric\n",
    "!pip install -q highway-env gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8352576f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:21:34.412838Z",
     "iopub.status.busy": "2026-01-02T05:21:34.412239Z",
     "iopub.status.idle": "2026-01-02T05:21:35.682322Z",
     "shell.execute_reply": "2026-01-02T05:21:35.681461Z"
    },
    "papermill": {
     "duration": 1.280805,
     "end_time": "2026-01-02T05:21:35.683821",
     "exception": false,
     "start_time": "2026-01-02T05:21:34.403016",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'WorldModel-Self-Driving-Car'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "rm -rf WorldModel-Self-Driving-Car\n",
    "git clone -b debug_branch https://github.com/CS-3331-Fundamental-of-AI/WorldModel-Self-Driving-Car.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59195c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:21:35.702052Z",
     "iopub.status.busy": "2026-01-02T05:21:35.701517Z",
     "iopub.status.idle": "2026-01-02T05:21:35.706475Z",
     "shell.execute_reply": "2026-01-02T05:21:35.705838Z"
    },
    "papermill": {
     "duration": 0.015323,
     "end_time": "2026-01-02T05:21:35.707795",
     "exception": false,
     "start_time": "2026-01-02T05:21:35.692472",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/WorldModel-Self-Driving-Car\n"
     ]
    }
   ],
   "source": [
    "cd WorldModel-Self-Driving-Car\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0c5cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:21:35.726196Z",
     "iopub.status.busy": "2026-01-02T05:21:35.725718Z",
     "iopub.status.idle": "2026-01-02T05:23:02.670791Z",
     "shell.execute_reply": "2026-01-02T05:23:02.669909Z"
    },
    "papermill": {
     "duration": 86.95598,
     "end_time": "2026-01-02T05:23:02.672758",
     "exception": false,
     "start_time": "2026-01-02T05:21:35.716778",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.3.1 (from -r requirements.txt (line 1))\r\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting aiofiles==25.1.0 (from -r requirements.txt (line 2))\r\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.6.1)\r\n",
      "Requirement already satisfied: aiohttp==3.13.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.13.2)\r\n",
      "Requirement already satisfied: aiosignal==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: ale-py==0.11.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.11.2)\r\n",
      "Collecting anyio==4.11.0 (from -r requirements.txt (line 7))\r\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Collecting appnope==0.1.4 (from -r requirements.txt (line 8))\r\n",
      "  Downloading appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\r\n",
      "Requirement already satisfied: argon2-cffi==25.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (25.1.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings==25.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (25.1.0)\r\n",
      "Collecting array-api-compat==1.12.0 (from -r requirements.txt (line 11))\r\n",
      "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: arrow==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.4.0)\r\n",
      "Collecting asttokens==3.0.0 (from -r requirements.txt (line 13))\r\n",
      "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting async-lru==2.0.5 (from -r requirements.txt (line 14))\r\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: attrs==25.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (25.4.0)\r\n",
      "Requirement already satisfied: babel==2.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.17.0)\r\n",
      "Collecting beautifulsoup4==4.14.2 (from -r requirements.txt (line 17))\r\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting bleach==6.3.0 (from -r requirements.txt (line 18))\r\n",
      "  Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\r\n",
      "Collecting box2d-py==2.3.5 (from -r requirements.txt (line 19))\r\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: branca==0.8.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.8.2)\r\n",
      "Collecting certifi==2025.10.5 (from -r requirements.txt (line 21))\r\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: cffi==2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer==3.4.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (3.4.4)\r\n",
      "Collecting chex==0.1.91 (from -r requirements.txt (line 24))\r\n",
      "  Downloading chex-0.1.91-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: cloudpickle==3.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (3.1.1)\r\n",
      "Collecting comet_ml==3.54.1 (from -r requirements.txt (line 26))\r\n",
      "  Downloading comet_ml-3.54.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: comm==0.2.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (0.2.3)\r\n",
      "Collecting configobj==5.0.9 (from -r requirements.txt (line 28))\r\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (1.3.3)\r\n",
      "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (0.12.1)\r\n",
      "Collecting debugpy==1.8.17 (from -r requirements.txt (line 31))\r\n",
      "  Downloading debugpy-1.8.17-cp312-cp312-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting decorator==5.2.1 (from -r requirements.txt (line 32))\r\n",
      "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (0.7.1)\r\n",
      "Collecting dulwich==0.24.10 (from -r requirements.txt (line 34))\r\n",
      "  Downloading dulwich-0.24.10-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: etils==1.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (1.13.0)\r\n",
      "Collecting everett==3.1.0 (from -r requirements.txt (line 36))\r\n",
      "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting executing==2.2.1 (from -r requirements.txt (line 37))\r\n",
      "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\r\n",
      "Requirement already satisfied: Farama-Notifications==0.0.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (0.0.4)\r\n",
      "Requirement already satisfied: fastjsonschema==2.21.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (2.21.2)\r\n",
      "Collecting filelock==3.20.0 (from -r requirements.txt (line 40))\r\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting flax==0.12.0 (from -r requirements.txt (line 41))\r\n",
      "  Downloading flax-0.12.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: folium==0.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (0.20.0)\r\n",
      "Requirement already satisfied: fonttools==4.60.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (4.60.1)\r\n",
      "Requirement already satisfied: fqdn==1.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (1.5.1)\r\n",
      "Requirement already satisfied: frozenlist==1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 45)) (1.8.0)\r\n",
      "Collecting fsspec==2025.9.0 (from -r requirements.txt (line 46))\r\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting glfw==2.10.0 (from -r requirements.txt (line 47))\r\n",
      "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\r\n",
      "Collecting grpcio==1.76.0 (from -r requirements.txt (line 48))\r\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\r\n",
      "Collecting gymnasium==1.2.1 (from -r requirements.txt (line 49))\r\n",
      "  Downloading gymnasium-1.2.1-py3-none-any.whl.metadata (10.0 kB)\r\n",
      "Requirement already satisfied: h11==0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 50)) (0.16.0)\r\n",
      "Requirement already satisfied: highway-env==1.10.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (1.10.2)\r\n",
      "Requirement already satisfied: httpcore==1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 52)) (1.0.9)\r\n",
      "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 53)) (0.28.1)\r\n",
      "Requirement already satisfied: humanize==4.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 54)) (4.14.0)\r\n",
      "Requirement already satisfied: idna==3.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 55)) (3.11)\r\n",
      "Requirement already satisfied: imageio==2.37.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 56)) (2.37.0)\r\n",
      "Requirement already satisfied: imageio-ffmpeg==0.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 57)) (0.6.0)\r\n",
      "Requirement already satisfied: importlib_resources==6.5.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 58)) (6.5.2)\r\n",
      "Requirement already satisfied: iniconfig==2.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 59)) (2.3.0)\r\n",
      "Collecting ipykernel==7.1.0 (from -r requirements.txt (line 60))\r\n",
      "  Downloading ipykernel-7.1.0-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Collecting ipython==9.6.0 (from -r requirements.txt (line 61))\r\n",
      "  Downloading ipython-9.6.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 62)) (1.1.1)\r\n",
      "Requirement already satisfied: isoduration==20.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 63)) (20.11.0)\r\n",
      "Collecting jax==0.8.0 (from -r requirements.txt (line 64))\r\n",
      "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting jaxlib==0.8.0 (from -r requirements.txt (line 65))\r\n",
      "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: jedi==0.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 66)) (0.19.2)\r\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 67)) (3.1.6)\r\n",
      "Collecting joblib==1.5.2 (from -r requirements.txt (line 68))\r\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: json5==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 69)) (0.12.1)\r\n",
      "Requirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 70)) (1.33)\r\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 71)) (3.0.0)\r\n",
      "Requirement already satisfied: jsonschema==4.25.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 72)) (4.25.1)\r\n",
      "Requirement already satisfied: jsonschema-specifications==2025.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 73)) (2025.9.1)\r\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 74)) (0.12.0)\r\n",
      "Collecting jupyter-lsp==2.3.0 (from -r requirements.txt (line 75))\r\n",
      "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting jupyter_client==8.6.3 (from -r requirements.txt (line 76))\r\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: jupyter_core==5.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 77)) (5.9.1)\r\n",
      "Collecting jupyter_server==2.17.0 (from -r requirements.txt (line 78))\r\n",
      "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 79)) (0.5.3)\r\n",
      "Collecting jupyterlab==4.4.10 (from -r requirements.txt (line 80))\r\n",
      "  Downloading jupyterlab-4.4.10-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 81)) (0.3.0)\r\n",
      "Requirement already satisfied: jupyterlab_server==2.28.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 82)) (2.28.0)\r\n",
      "Requirement already satisfied: kagglehub==0.3.13 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 83)) (0.3.13)\r\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 84)) (1.4.9)\r\n",
      "Collecting lark==1.3.1 (from -r requirements.txt (line 85))\r\n",
      "  Downloading lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: lazy_loader==0.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 86)) (0.4)\r\n",
      "Collecting llvmlite==0.45.1 (from -r requirements.txt (line 87))\r\n",
      "  Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\r\n",
      "Collecting Markdown==3.10 (from -r requirements.txt (line 88))\r\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: markdown-it-py==4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 89)) (4.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 90)) (3.0.3)\r\n",
      "Collecting matplotlib==3.10.7 (from -r requirements.txt (line 91))\r\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting matplotlib-inline==0.2.1 (from -r requirements.txt (line 92))\r\n",
      "  Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 93)) (0.1.2)\r\n",
      "Collecting mistune==3.1.4 (from -r requirements.txt (line 94))\r\n",
      "  Downloading mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: ml_dtypes==0.5.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 95)) (0.5.3)\r\n",
      "Collecting moviepy==2.2.1 (from -r requirements.txt (line 96))\r\n",
      "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 97)) (1.3.0)\r\n",
      "Requirement already satisfied: msgpack==1.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 98)) (1.1.2)\r\n",
      "Collecting mujoco==3.3.7 (from -r requirements.txt (line 99))\r\n",
      "  Downloading mujoco-3.3.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: multidict==6.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 100)) (6.7.0)\r\n",
      "Collecting nbclient==0.10.2 (from -r requirements.txt (line 101))\r\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting nbconvert==7.16.6 (from -r requirements.txt (line 102))\r\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: nbformat==5.10.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 103)) (5.10.4)\r\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 104)) (1.6.0)\r\n",
      "Requirement already satisfied: networkx==3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 105)) (3.5)\r\n",
      "Collecting notebook==7.4.7 (from -r requirements.txt (line 106))\r\n",
      "  Downloading notebook-7.4.7-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 107)) (0.2.4)\r\n",
      "Collecting numba==0.62.1 (from -r requirements.txt (line 108))\r\n",
      "  Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\r\n",
      "Collecting numpy==2.2.6 (from -r requirements.txt (line 109))\r\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python==4.12.0.88 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 110)) (4.12.0.88)\r\n",
      "Requirement already satisfied: opt_einsum==3.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 111)) (3.4.0)\r\n",
      "Requirement already satisfied: optax==0.2.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 112)) (0.2.6)\r\n",
      "Requirement already satisfied: orbax-checkpoint==0.11.25 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 113)) (0.11.25)\r\n",
      "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 114)) (25.0)\r\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 115))\r\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 116)) (1.5.1)\r\n",
      "Requirement already satisfied: parso==0.8.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 117)) (0.8.5)\r\n",
      "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 118)) (4.9.0)\r\n",
      "Requirement already satisfied: pillow==11.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 119)) (11.3.0)\r\n",
      "Collecting platformdirs==4.5.0 (from -r requirements.txt (line 120))\r\n",
      "  Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: pluggy==1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 121)) (1.6.0)\r\n",
      "Collecting polars==1.35.2 (from -r requirements.txt (line 122))\r\n",
      "  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting polars-runtime-32==1.35.2 (from -r requirements.txt (line 123))\r\n",
      "  Downloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: proglog==0.1.12 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 124)) (0.1.12)\r\n",
      "Requirement already satisfied: prometheus_client==0.23.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 125)) (0.23.1)\r\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 126)) (3.0.52)\r\n",
      "Requirement already satisfied: propcache==0.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 127)) (0.4.1)\r\n",
      "Collecting protobuf==6.33.0 (from -r requirements.txt (line 128))\r\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\r\n",
      "Collecting psutil==7.1.2 (from -r requirements.txt (line 129))\r\n",
      "  Downloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 130)) (0.7.0)\r\n",
      "Collecting pure_eval==0.2.3 (from -r requirements.txt (line 131))\r\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: pycparser==2.23 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 132)) (2.23)\r\n",
      "Requirement already satisfied: pygame==2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 133)) (2.6.1)\r\n",
      "Requirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 134)) (2.19.2)\r\n",
      "Requirement already satisfied: PyOpenGL==3.1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 135)) (3.1.10)\r\n",
      "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 136)) (3.2.5)\r\n",
      "Requirement already satisfied: pytest==8.4.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 137)) (8.4.2)\r\n",
      "Collecting python-box==6.1.0 (from -r requirements.txt (line 138))\r\n",
      "  Downloading python_box-6.1.0-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 139)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-dotenv==1.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 140)) (1.1.1)\r\n",
      "Requirement already satisfied: python-json-logger==4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 141)) (4.0.0)\r\n",
      "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 142)) (2025.2)\r\n",
      "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 143)) (6.0.3)\r\n",
      "Collecting pyzmq==27.1.0 (from -r requirements.txt (line 144))\r\n",
      "  Downloading pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\r\n",
      "Requirement already satisfied: referencing==0.37.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 145)) (0.37.0)\r\n",
      "Requirement already satisfied: requests==2.32.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 146)) (2.32.5)\r\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 147)) (1.0.0)\r\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 148)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 149)) (0.1.1)\r\n",
      "Requirement already satisfied: rfc3987-syntax==1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 150)) (1.1.0)\r\n",
      "Requirement already satisfied: rich==14.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 151)) (14.2.0)\r\n",
      "Collecting rpds-py==0.28.0 (from -r requirements.txt (line 152))\r\n",
      "  Downloading rpds_py-0.28.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\r\n",
      "Collecting ruamel.yaml==0.18.16 (from -r requirements.txt (line 153))\r\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting ruamel.yaml.clib==0.2.15 (from -r requirements.txt (line 154))\r\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: scikit-image==0.25.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 155)) (0.25.2)\r\n",
      "Collecting scikit-learn==1.7.2 (from -r requirements.txt (line 156))\r\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting scipy==1.16.2 (from -r requirements.txt (line 157))\r\n",
      "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: semantic-version==2.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 158)) (2.10.0)\r\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 159)) (1.8.3)\r\n",
      "Collecting sentry-sdk==2.45.0 (from -r requirements.txt (line 160))\r\n",
      "  Downloading sentry_sdk-2.45.0-py2.py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting setuptools==80.9.0 (from -r requirements.txt (line 161))\r\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: simplejson==3.20.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 162)) (3.20.2)\r\n",
      "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 163)) (1.17.0)\r\n",
      "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 164)) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve==2.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 165)) (2.8)\r\n",
      "Collecting stack-data==0.6.3 (from -r requirements.txt (line 166))\r\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting swig==4.3.1.post0 (from -r requirements.txt (line 167))\r\n",
      "  Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\r\n",
      "Collecting sympy==1.14.0 (from -r requirements.txt (line 168))\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting tensorboard==2.20.0 (from -r requirements.txt (line 169))\r\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 170)) (0.7.2)\r\n",
      "Requirement already satisfied: tensorstore==0.1.78 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 171)) (0.1.78)\r\n",
      "Requirement already satisfied: terminado==0.18.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 172)) (0.18.1)\r\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 173)) (3.6.0)\r\n",
      "Requirement already satisfied: tifffile==2025.10.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 174)) (2025.10.16)\r\n",
      "Requirement already satisfied: tinycss2==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 175)) (1.4.0)\r\n",
      "Collecting toolz==1.1.0 (from -r requirements.txt (line 176))\r\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting torch==2.9.1 (from -r requirements.txt (line 177))\r\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: torch-geometric==2.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 178)) (2.7.0)\r\n",
      "Collecting torchvision==0.24.1 (from -r requirements.txt (line 179))\r\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\r\n",
      "Collecting tornado==6.5.2 (from -r requirements.txt (line 180))\r\n",
      "  Downloading tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 181)) (4.67.1)\r\n",
      "Collecting traitlets==5.14.3 (from -r requirements.txt (line 182))\r\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: treescope==0.1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 183)) (0.1.10)\r\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 184)) (4.15.0)\r\n",
      "Collecting tzdata==2025.2 (from -r requirements.txt (line 185))\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting ultralytics==8.3.231 (from -r requirements.txt (line 186))\r\n",
      "  Downloading ultralytics-8.3.231-py3-none-any.whl.metadata (37 kB)\r\n",
      "Collecting ultralytics-thop==2.0.18 (from -r requirements.txt (line 187))\r\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: uri-template==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 188)) (1.3.0)\r\n",
      "Collecting urllib3==2.5.0 (from -r requirements.txt (line 189))\r\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting visdom==0.2.4 (from -r requirements.txt (line 190))\r\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: wcwidth==0.2.14 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 191)) (0.2.14)\r\n",
      "Collecting webcolors==25.10.0 (from -r requirements.txt (line 192))\r\n",
      "  Downloading webcolors-25.10.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 193)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==1.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 194)) (1.9.0)\r\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 195)) (3.1.3)\r\n",
      "Requirement already satisfied: wheel==0.45.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 196)) (0.45.1)\r\n",
      "Collecting wrapt==2.0.1 (from -r requirements.txt (line 197))\r\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: wurlitzer==3.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 198)) (3.1.1)\r\n",
      "Requirement already satisfied: xxhash==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 199)) (3.6.0)\r\n",
      "Collecting xyzservices==2025.10.0 (from -r requirements.txt (line 200))\r\n",
      "  Downloading xyzservices-2025.10.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: yarl==1.22.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 201)) (1.22.0)\r\n",
      "Requirement already satisfied: zipp==3.23.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 202)) (3.23.0)\r\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 203)) (0.9.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 177)) (9.10.2.21)\r\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 177)) (0.7.1)\r\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==3.5.1 (from torch==2.9.1->-r requirements.txt (line 177))\r\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\r\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\r\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\r\n",
      "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\r\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\r\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bleach-6.3.0-py3-none-any.whl (164 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2025.10.5-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chex-0.1.91-py3-none-any.whl (100 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading comet_ml-3.54.1-py3-none-any.whl (775 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\r\n",
      "Downloading debugpy-1.8.17-cp312-cp312-manylinux_2_34_x86_64.whl (4.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\r\n",
      "Downloading dulwich-0.24.10-cp312-cp312-manylinux_2_28_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\r\n",
      "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\r\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading flax-0.12.0-py3-none-any.whl (466 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gymnasium-1.2.1-py3-none-any.whl (951 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.1/951.1 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ipykernel-7.1.0-py3-none-any.whl (117 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ipython-9.6.0-py3-none-any.whl (616 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jax-0.8.0-py3-none-any.whl (2.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl (79.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab-4.4.10-py3-none-any.whl (12.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lark-1.3.1-py3-none-any.whl (113 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\r\n",
      "Downloading mistune-3.1.4-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading moviepy-2.2.1-py3-none-any.whl (129 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mujoco-3.3.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nbclient-0.10.2-py3-none-any.whl (25 kB)\r\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading notebook-7.4.7-py3-none-any.whl (14.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading polars-1.35.2-py3-none-any.whl (783 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (258 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.7/258.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\r\n",
      "Downloading python_box-6.1.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (840 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.0/841.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rpds_py-0.28.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentry_sdk-2.45.0-py2.py3-none-any.whl (404 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.8/404.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\r\n",
      "Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading toolz-1.1.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m439.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m112.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics-8.3.231-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\r\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading webcolors-25.10.0-py3-none-any.whl (14 kB)\r\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xyzservices-2025.10.0-py3-none-any.whl (92 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: box2d-py, visdom\r\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\r\n",
      "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\r\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=99ca1e52a73f6ccd47dfbde37f231603e9a35669230d04b0d8bfa0eb700f1a24\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/37/6c/38/64eeaa310e325aacda723e6df1f79ab5e9f31ba195264e04a8\r\n",
      "Successfully built visdom\r\n",
      "Failed to build box2d-py\r\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcad730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:02.779717Z",
     "iopub.status.busy": "2026-01-02T05:23:02.779064Z",
     "iopub.status.idle": "2026-01-02T05:23:12.132653Z",
     "shell.execute_reply": "2026-01-02T05:23:12.131703Z"
    },
    "papermill": {
     "duration": 9.406549,
     "end_time": "2026-01-02T05:23:12.134478",
     "exception": false,
     "start_time": "2026-01-02T05:23:02.727929",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ruamel.yaml==0.18.16\r\n",
      "  Using cached ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting ruamel.yaml.clib==0.2.15\r\n",
      "  Using cached ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\r\n",
      "Using cached ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\r\n",
      "Using cached ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\r\n",
      "Installing collected packages: ruamel.yaml.clib, ruamel.yaml\r\n",
      "Successfully installed ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.15\r\n",
      "Collecting comet_ml\r\n",
      "  Downloading comet_ml-3.55.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\r\n",
      "  Downloading dulwich-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\r\n",
      "  Using cached everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (4.25.1)\r\n",
      "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (5.9.5)\r\n",
      "Collecting python-box<7.0.0 (from comet_ml)\r\n",
      "  Using cached python_box-6.1.0-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.32.5)\r\n",
      "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (14.2.0)\r\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.10.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.42.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from comet_ml) (75.2.0)\r\n",
      "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from comet_ml) (3.20.2)\r\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.6.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.0.0)\r\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (3.1.1)\r\n",
      "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\r\n",
      "  Using cached configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (25.4.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.27.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (3.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (2025.11.12)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet_ml) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet_ml) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema!=3.1.0,>=2.6.0->comet_ml) (4.15.0)\r\n",
      "Downloading comet_ml-3.55.0-py3-none-any.whl (780 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dulwich-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hUsing cached everett-3.1.0-py2.py3-none-any.whl (35 kB)\r\n",
      "Using cached python_box-6.1.0-py3-none-any.whl (27 kB)\r\n",
      "Using cached configobj-5.0.9-py2.py3-none-any.whl (35 kB)\r\n",
      "Installing collected packages: everett, python-box, dulwich, configobj, comet_ml\r\n",
      "  Attempting uninstall: python-box\r\n",
      "    Found existing installation: python-box 7.3.2\r\n",
      "    Uninstalling python-box-7.3.2:\r\n",
      "      Successfully uninstalled python-box-7.3.2\r\n",
      "Successfully installed comet_ml-3.55.0 configobj-5.0.9 dulwich-0.25.0 everett-3.1.0 python-box-6.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ruamel.yaml==0.18.16 ruamel.yaml.clib==0.2.15\n",
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe016dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:12.233471Z",
     "iopub.status.busy": "2026-01-02T05:23:12.232820Z",
     "iopub.status.idle": "2026-01-02T05:23:12.243196Z",
     "shell.execute_reply": "2026-01-02T05:23:12.242661Z"
    },
    "papermill": {
     "duration": 0.060588,
     "end_time": "2026-01-02T05:23:12.244624",
     "exception": false,
     "start_time": "2026-01-02T05:23:12.184036",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working/WorldModel-Self-Driving-Car\n",
    "cat << 'EOF' > ./.env\n",
    "WORK_SPACE=dtj-tran\n",
    "API_KEY=Raze72byBUZdn5cWyLf3IFZ4h\n",
    "PROJECT_NAME=hanoiworld\n",
    "KAGGLE_KERNEL_RUN_TYPE=1\n",
    "USE_BF16=True\n",
    "JEPA_CKPT_ROOT=/kaggle/input/jepa-ckpt-5k/pytorch/default/1\n",
    "MAP_ROOT=/kaggle/input/a-crude-data-set-converted-from-nuscene/local_maps\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4d2c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:12.345289Z",
     "iopub.status.busy": "2026-01-02T05:23:12.344702Z",
     "iopub.status.idle": "2026-01-02T05:23:12.366346Z",
     "shell.execute_reply": "2026-01-02T05:23:12.365615Z"
    },
    "papermill": {
     "duration": 0.073526,
     "end_time": "2026-01-02T05:23:12.367839",
     "exception": false,
     "start_time": "2026-01-02T05:23:12.294313",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa597e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:12.467292Z",
     "iopub.status.busy": "2026-01-02T05:23:12.466739Z",
     "iopub.status.idle": "2026-01-02T05:23:16.091339Z",
     "shell.execute_reply": "2026-01-02T05:23:16.090578Z"
    },
    "papermill": {
     "duration": 3.676436,
     "end_time": "2026-01-02T05:23:16.093066",
     "exception": false,
     "start_time": "2026-01-02T05:23:12.416630",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/WorldModel-Self-Driving-Car/HanoiWorld\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment two-way-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Standalone evaluation script for DreamerV3 trained models.\n",
    "Loads a checkpoint and runs evaluation episodes with visualization.\n",
    "\"\"\"\n",
    "%cd HanoiWorld\n",
    "import os\n",
    "\n",
    "# os.chdir(\"HanoiWorld\")\n",
    "\n",
    "import argparse\n",
    "import functools\n",
    "import pathlib\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# import tools\n",
    "from envs.highway import HighwayEnv\n",
    "from envs.highway_base import ENV_NAME_MAPPING\n",
    "# from HanoiAgent import HanoiAgent\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "def load_config(config_names):\n",
    "    \"\"\"Load config from configs.yaml using the same method as dreamer.py.\"\"\"\n",
    "    yaml_loader = YAML(typ=\"safe\")\n",
    "    configs = yaml_loader.load((pathlib.Path(__file__).parent / \"configs.yaml\").read_text())\n",
    "    \n",
    "    def recursive_update(base, update):\n",
    "        for key, value in update.items():\n",
    "            if isinstance(value, dict) and key in base:\n",
    "                recursive_update(base[key], value)\n",
    "            else:\n",
    "                base[key] = value\n",
    "    \n",
    "    name_list = [\"defaults\", *config_names] if config_names else [\"defaults\"]\n",
    "    defaults = {}\n",
    "    for name in name_list:\n",
    "        if name in configs:\n",
    "            recursive_update(defaults, configs[name])\n",
    "    \n",
    "    # Convert to argparse namespace (same as dreamer.py)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    for key, value in sorted(defaults.items(), key=lambda x: x[0]):\n",
    "        arg_type = args_type(value)\n",
    "        parser.add_argument(f\"--{key}\", type=arg_type, default=arg_type(value))\n",
    "    \n",
    "    config = parser.parse_args([])\n",
    "    return config\n",
    "\n",
    "def make_env(config, render=False):\n",
    "    \"\"\"Create environment based on task.\"\"\"\n",
    "    task = config.task\n",
    "\n",
    "    # Highway-family tasks\n",
    "    if task.startswith(\"highway_\"):\n",
    "        env_name = task.split(\"_\", 1)[1]\n",
    "    elif task in ENV_NAME_MAPPING:\n",
    "        env_name = task\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "    # Choose render_mode\n",
    "    if render:\n",
    "        render_mode = \"human\"        # visualize with window\n",
    "    else:\n",
    "        render_mode = \"rgb_array\"    # off-screen; no window\n",
    "\n",
    "    env = HighwayEnv(\n",
    "        name=env_name,\n",
    "        size=tuple(config.size) if hasattr(config, \"size\") else (64, 64),\n",
    "        obs_type=getattr(config, \"highway_obs_type\", \"image\"),\n",
    "        action_type=getattr(config, \"highway_action_type\", \"discrete\"),\n",
    "        action_repeat=config.action_repeat,\n",
    "        vehicles_count=getattr(config, \"highway_vehicles_count\", 50),\n",
    "        vehicles_density=getattr(config, \"highway_vehicles_density\", 1.5),\n",
    "        use_reward_shaping=getattr(config, \"highway_reward_shaping\", True),\n",
    "        render_mode=render_mode,     # <--- Added param\n",
    "        offscreen_rendering=not getattr(config, \"highway_visualize\", False),\n",
    "    )\n",
    "    return env\n",
    "\n",
    "# Create dummy logger\n",
    "class DummyLogger:\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "    def scalar(self, *args, **kwargs): pass\n",
    "    def image(self, *args, **kwargs): pass\n",
    "    def video(self, *args, **kwargs): pass\n",
    "    def write(self, *args, **kwargs): pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223d5d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:16.193846Z",
     "iopub.status.busy": "2026-01-02T05:23:16.192878Z",
     "iopub.status.idle": "2026-01-02T05:23:16.198267Z",
     "shell.execute_reply": "2026-01-02T05:23:16.197580Z"
    },
    "papermill": {
     "duration": 0.05632,
     "end_time": "2026-01-02T05:23:16.199651",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.143331",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/kaggle/working/WorldModel-Self-Driving-Car')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path.cwd().parent   # or .parent.parent if needed\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c67b1c",
   "metadata": {
    "papermill": {
     "duration": 0.048667,
     "end_time": "2026-01-02T05:23:16.297396",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.248729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d469fae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:16.396410Z",
     "iopub.status.busy": "2026-01-02T05:23:16.396077Z",
     "iopub.status.idle": "2026-01-02T05:23:16.444368Z",
     "shell.execute_reply": "2026-01-02T05:23:16.443668Z"
    },
    "papermill": {
     "duration": 0.099935,
     "end_time": "2026-01-02T05:23:16.445666",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.345731",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/WorldModel-Self-Driving-Car/HanoiWorld\n"
     ]
    }
   ],
   "source": [
    "%cd  /kaggle/working/WorldModel-Self-Driving-Car/HanoiWorld\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as torchd\n",
    "from GRU import GRUCell\n",
    "# import tools\n",
    "\n",
    "class RSSM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        stoch=30, # Number of stochastic latent units\n",
    "        deter=200, # Size of deterministic hidden state in the GRU.\n",
    "        hidden=200, #  Size of intermediate MLP layers in the RSSM.\n",
    "        rec_depth=1, # How many times to apply the GRU per time-step.\n",
    "        discrete=False, # Whether to use discrete latent states.\n",
    "        act=\"SiLU\", # Activation function inside layers.\n",
    "        norm=True, # Apply layer normalization to stabilize training.\n",
    "        mean_act=\"none\", # Applies an activation to the mean of the Gaussian latent.\n",
    "        std_act=\"softplus\", # How to transform raw outputs into positive standard deviations.\n",
    "        min_std=0.1, # Ensures std never becomes 0:\n",
    "        unimix_ratio=0.01,  # Used only when discrete=True.\n",
    "        initial=\"learned\",  # How to initialize the first hidden state -  train a special learnable vector W\n",
    "        num_actions=None, # Dimension of action vector.\n",
    "        embed=None, # The embedding dimension of observations.\n",
    "        device=None, # cuda / cpu\n",
    "    ):\n",
    "        super(RSSM, self).__init__()\n",
    "        self._stoch = stoch\n",
    "        self._deter = deter\n",
    "        self._hidden = hidden\n",
    "        self._min_std = min_std\n",
    "        self._rec_depth = rec_depth\n",
    "        self._discrete = discrete\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._mean_act = mean_act\n",
    "        self._std_act = std_act\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._initial = initial\n",
    "        self._num_actions = num_actions\n",
    "        self._embed = embed\n",
    "        self._device = device\n",
    "\n",
    "        inp_layers = []\n",
    "        if self._discrete:\n",
    "            inp_dim = self._stoch * self._discrete + num_actions\n",
    "        else:\n",
    "            inp_dim = self._stoch + num_actions\n",
    "        inp_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            inp_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        inp_layers.append(act())\n",
    "        self._img_in_layers = nn.Sequential(*inp_layers)\n",
    "        self._img_in_layers.apply(weight_init)\n",
    "        self._cell = GRUCell(self._hidden, self._deter, norm=norm)\n",
    "        self._cell.apply(weight_init)\n",
    "\n",
    "        img_out_layers = []\n",
    "        inp_dim = self._deter\n",
    "        img_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            img_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        img_out_layers.append(act())\n",
    "        self._img_out_layers = nn.Sequential(*img_out_layers)\n",
    "        self._img_out_layers.apply(weight_init)\n",
    "\n",
    "        obs_out_layers = []\n",
    "        inp_dim = self._deter + self._embed\n",
    "        obs_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            obs_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        obs_out_layers.append(act())\n",
    "        self._obs_out_layers = nn.Sequential(*obs_out_layers)\n",
    "        self._obs_out_layers.apply(weight_init)\n",
    "\n",
    "        if self._discrete:\n",
    "            self._imgs_stat_layer = nn.Linear(\n",
    "                self._hidden, self._stoch * self._discrete\n",
    "            )\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, self._stoch * self._discrete)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "        else:\n",
    "            self._imgs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "\n",
    "        if self._initial == \"learned\":\n",
    "            self.W = torch.nn.Parameter(\n",
    "                torch.zeros((1, self._deter), device=torch.device(self._device)),\n",
    "                requires_grad=True,\n",
    "            )\n",
    "\n",
    "    def initial(self, batch_size):\n",
    "        deter = torch.zeros(batch_size, self._deter, device=self._device)\n",
    "        if self._discrete:\n",
    "            state = dict(\n",
    "                logit=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                stoch=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                deter=deter,\n",
    "            )\n",
    "        else:\n",
    "            state = dict(\n",
    "                mean=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                std=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                stoch=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                deter=deter,\n",
    "            )\n",
    "        if self._initial == \"zeros\":\n",
    "            return state\n",
    "        elif self._initial == \"learned\":\n",
    "            state[\"deter\"] = torch.tanh(self.W).repeat(batch_size, 1)\n",
    "            state[\"stoch\"] = self.get_stoch(state[\"deter\"])\n",
    "            return state\n",
    "        else:\n",
    "            raise NotImplementedError(self._initial)\n",
    "\n",
    "    def observe(self, embed, action, is_first, state=None):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        # (batch, time, ch) -> (time, batch, ch)\n",
    "        embed, action, is_first = swap(embed), swap(action), swap(is_first)\n",
    "        # prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\n",
    "        post, prior = static_scan(\n",
    "            lambda prev_state, prev_act, embed, is_first: self.obs_step(\n",
    "                prev_state[0], prev_act, embed, is_first\n",
    "            ),\n",
    "            (action, embed, is_first),\n",
    "            (state, state),\n",
    "        )\n",
    "\n",
    "        # (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\n",
    "        post = {k: swap(v) for k, v in post.items()}\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return post, prior\n",
    "\n",
    "    def imagine_with_action(self, action, state):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        assert isinstance(state, dict), state\n",
    "        action = swap(action)\n",
    "        prior = static_scan(self.img_step, [action], state)\n",
    "        prior = prior[0]\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return prior\n",
    "\n",
    "    def get_feat(self, state):\n",
    "        stoch = state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            stoch = stoch.reshape(shape)\n",
    "        return torch.cat([stoch, state[\"deter\"]], -1)\n",
    "\n",
    "    def get_dist(self, state, dtype=None):\n",
    "        if self._discrete:\n",
    "            logit = state[\"logit\"]\n",
    "            dist = torchd.independent.Independent(\n",
    "                OneHotDist(logit, unimix_ratio=self._unimix_ratio), 1\n",
    "            )\n",
    "        else:\n",
    "            mean, std = state[\"mean\"], state[\"std\"]\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, std), 1)\n",
    "            )\n",
    "        return dist\n",
    "\n",
    "    def obs_step(self, prev_state, prev_action, embed, is_first, sample=True):\n",
    "        # this is for posterior update + prior propagation when \n",
    "        # initialize all prev_state\n",
    "        if prev_state == None or torch.sum(is_first) == len(is_first):\n",
    "            prev_state = self.initial(len(is_first))\n",
    "            prev_action = torch.zeros(\n",
    "                (len(is_first), self._num_actions), device=self._device\n",
    "            )\n",
    "        # overwrite the prev_state only where is_first=True\n",
    "        elif torch.sum(is_first) > 0:\n",
    "            is_first = is_first[:, None]\n",
    "            prev_action *= 1.0 - is_first\n",
    "            init_state = self.initial(len(is_first))\n",
    "            for key, val in prev_state.items():\n",
    "                is_first_r = torch.reshape(\n",
    "                    is_first,\n",
    "                    is_first.shape + (1,) * (len(val.shape) - len(is_first.shape)),\n",
    "                )\n",
    "                prev_state[key] = (\n",
    "                    val * (1.0 - is_first_r) + init_state[key] * is_first_r\n",
    "                )\n",
    "\n",
    "        prior = self.img_step(prev_state, prev_action)\n",
    "        # print(\"DEBUG RSSM !\")\n",
    "        # print(f\"deter shape {prior[\"deter\"].shape}\")\n",
    "        # print(f\"embed shape {embed.shape}\")\n",
    "        x = torch.cat([prior[\"deter\"], embed], -1)\n",
    "        # (batch_size, prior_deter + embed) -> (batch_size, hidden)\n",
    "        x = self._obs_out_layers(x)\n",
    "        # (batch_size, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"obs\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        post = {\"stoch\": stoch, \"deter\": prior[\"deter\"], **stats}\n",
    "        return post, prior\n",
    "\n",
    "    def img_step(self, prev_state, prev_action, sample=True):\n",
    "        # (batch, stoch, discrete_num) - the transition model/ prior - the way model predict next\n",
    "        # latent state | prev latent & action & no observation\n",
    "        prev_stoch = prev_state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(prev_stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            # (batch, stoch, discrete_num) -> (batch, stoch * discrete_num)\n",
    "            prev_stoch = prev_stoch.reshape(shape)\n",
    "        # (batch, stoch * discrete_num) -> (batch, stoch * discrete_num + action)\n",
    "        x = torch.cat([prev_stoch, prev_action], -1)\n",
    "        # (batch, stoch * discrete_num + action, embed) -> (batch, hidden)\n",
    "        x = self._img_in_layers(x)\n",
    "        for _ in range(self._rec_depth):  # rec depth is not correctly implemented\n",
    "            deter = prev_state[\"deter\"]\n",
    "            # (batch, hidden), (batch, deter) -> (batch, deter), (batch, deter)\n",
    "            x, deter = self._cell(x, [deter])\n",
    "            deter = deter[0]  # Keras wraps the state in a list.\n",
    "        # (batch, deter) -> (batch, hidden)\n",
    "        x = self._img_out_layers(x)\n",
    "        # (batch, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        prior = {\"stoch\": stoch, \"deter\": deter, **stats}\n",
    "        return prior\n",
    "\n",
    "    def get_stoch(self, deter):\n",
    "        # input deterministic state -> return the stochastic state\n",
    "        x = self._img_out_layers(deter)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        dist = self.get_dist(stats)\n",
    "        return dist.mode()\n",
    "\n",
    "    def _suff_stats_layer(self, name, x):\n",
    "        if self._discrete:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            logit = x.reshape(list(x.shape[:-1]) + [self._stoch, self._discrete])\n",
    "            return {\"logit\": logit}\n",
    "        else:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            mean, std = torch.split(x, [self._stoch] * 2, -1)\n",
    "            mean = {\n",
    "                \"none\": lambda: mean,\n",
    "                \"tanh5\": lambda: 5.0 * torch.tanh(mean / 5.0),\n",
    "            }[self._mean_act]()\n",
    "            std = {\n",
    "                \"softplus\": lambda: torch.softplus(std),\n",
    "                \"abs\": lambda: torch.abs(std + 1),\n",
    "                \"sigmoid\": lambda: torch.sigmoid(std),\n",
    "                \"sigmoid2\": lambda: 2 * torch.sigmoid(std / 2),\n",
    "            }[self._std_act]()\n",
    "            std = std + self._min_std\n",
    "            return {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    def kl_loss(self, post, prior, free, dyn_scale, rep_scale):\n",
    "        kld = torchd.kl.kl_divergence\n",
    "        dist = lambda x: self.get_dist(x)\n",
    "        sg = lambda x: {k: v.detach() for k, v in x.items()}\n",
    "\n",
    "        rep_loss = value = kld(\n",
    "            dist(post) if self._discrete else dist(post)._dist,\n",
    "            dist(sg(prior)) if self._discrete else dist(sg(prior))._dist,\n",
    "        )\n",
    "        dyn_loss = kld(\n",
    "            dist(sg(post)) if self._discrete else dist(sg(post))._dist,\n",
    "            dist(prior) if self._discrete else dist(prior)._dist,\n",
    "        )\n",
    "        # this is implemented using maximum at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        rep_loss = torch.clip(rep_loss, min=free)\n",
    "        dyn_loss = torch.clip(dyn_loss, min=free)\n",
    "        loss = dyn_scale * dyn_loss + rep_scale * rep_loss\n",
    "\n",
    "        return loss, value, dyn_loss, rep_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea571a10",
   "metadata": {
    "papermill": {
     "duration": 0.04836,
     "end_time": "2026-01-02T05:23:16.545002",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.496642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility for RSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d529fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:16.644503Z",
     "iopub.status.busy": "2026-01-02T05:23:16.643770Z",
     "iopub.status.idle": "2026-01-02T05:23:16.652947Z",
     "shell.execute_reply": "2026-01-02T05:23:16.652301Z"
    },
    "papermill": {
     "duration": 0.06102,
     "end_time": "2026-01-02T05:23:16.654270",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.593250",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "def wrap_angle(a):\n",
    "    return (a + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "class TrajectoryBuffer:\n",
    "    def __init__(self, T=8):\n",
    "        self.T = T\n",
    "        self.buf = deque(maxlen=T)\n",
    "        self.prev_state = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.buf.clear()\n",
    "        self.prev_state = None\n",
    "\n",
    "    def step(self, ego_state, lane):\n",
    "        if self.prev_state is None:\n",
    "            self.prev_state = {\n",
    "                \"pos\": np.array(ego_state[\"pos\"], dtype=np.float32),\n",
    "                \"speed\": float(ego_state[\"speed\"]),\n",
    "                \"yaw\": float(ego_state[\"yaw\"]),\n",
    "            }\n",
    "            return\n",
    "\n",
    "        # Deltas\n",
    "        dx = ego_state[\"pos\"][0] - self.prev_state[\"pos\"][0]\n",
    "        dy = ego_state[\"pos\"][1] - self.prev_state[\"pos\"][1]\n",
    "        dv = ego_state[\"speed\"] - self.prev_state[\"speed\"]\n",
    "        dyaw = wrap_angle(ego_state[\"yaw\"] - self.prev_state[\"yaw\"])\n",
    "\n",
    "        # Frenet (lane-aligned)\n",
    "        if lane is not None and hasattr(lane, \"local_coordinates\"):\n",
    "            s_prev, d_prev = lane.local_coordinates(self.prev_state[\"pos\"])\n",
    "            s_curr, d_curr = lane.local_coordinates(ego_state[\"pos\"])\n",
    "            ds_forward = s_curr - s_prev\n",
    "            ds_side = d_curr - d_prev\n",
    "        else:\n",
    "            ds_forward = 0.0\n",
    "            ds_side = 0.0\n",
    "\n",
    "        vec = np.array(\n",
    "            [dx, dy, dv, dyaw, ds_forward, ds_side],\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.buf.append(vec)\n",
    "\n",
    "        self.prev_state = {\n",
    "            \"pos\": np.array(ego_state[\"pos\"], dtype=np.float32),\n",
    "            \"speed\": float(ego_state[\"speed\"]),\n",
    "            \"yaw\": float(ego_state[\"yaw\"]),\n",
    "        }\n",
    "\n",
    "    def get(self):\n",
    "        if len(self.buf) < self.T:\n",
    "            pad = [np.zeros(6, dtype=np.float32)] * (self.T - len(self.buf))\n",
    "            return np.stack(pad + list(self.buf), axis=0)\n",
    "        return np.stack(self.buf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36609c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:16.752938Z",
     "iopub.status.busy": "2026-01-02T05:23:16.752655Z",
     "iopub.status.idle": "2026-01-02T05:23:16.757378Z",
     "shell.execute_reply": "2026-01-02T05:23:16.756793Z"
    },
    "papermill": {
     "duration": 0.055543,
     "end_time": "2026-01-02T05:23:16.758737",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.703194",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ego_traj(prev, curr, dt=0.2):\n",
    "    dx = curr.x - prev.x\n",
    "    dy = curr.y - prev.y\n",
    "    dv = curr.speed - prev.speed\n",
    "    dyaw = wrap_angle(curr.heading - prev.heading)\n",
    "    ds_fwd = dx * np.cos(curr.heading) + dy * np.sin(curr.heading)\n",
    "    ds_lat = -dx * np.sin(curr.heading) + dy * np.cos(curr.heading)\n",
    "    return np.array([dx, dy, dv, dyaw, ds_fwd, ds_lat], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c014f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:16.858045Z",
     "iopub.status.busy": "2026-01-02T05:23:16.857761Z",
     "iopub.status.idle": "2026-01-02T05:23:31.240765Z",
     "shell.execute_reply": "2026-01-02T05:23:31.240066Z"
    },
    "papermill": {
     "duration": 14.434969,
     "end_time": "2026-01-02T05:23:31.242656",
     "exception": false,
     "start_time": "2026-01-02T05:23:16.807687",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 05:23:19.063192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767331399.256210      25 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767331399.310539      25 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767331399.784165      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767331399.784205      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767331399.784211      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767331399.784214      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import collections\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as torchd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def symlog(x):\n",
    "    return torch.sign(x) * torch.log(torch.abs(x) + 1.0)\n",
    "\n",
    "\n",
    "def symexp(x):\n",
    "    return torch.sign(x) * (torch.exp(torch.abs(x)) - 1.0)\n",
    "\n",
    "\n",
    "class RequiresGrad:\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._model.requires_grad_(requires_grad=True)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._model.requires_grad_(requires_grad=False)\n",
    "\n",
    "\n",
    "class TimeRecording:\n",
    "    def __init__(self, comment):\n",
    "        self._comment = comment\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._st = torch.cuda.Event(enable_timing=True)\n",
    "        self._nd = torch.cuda.Event(enable_timing=True)\n",
    "        self._st.record()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._nd.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(self._comment, self._st.elapsed_time(self._nd) / 1000)\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logdir, step):\n",
    "        self._logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=str(logdir), max_queue=1000)\n",
    "        self._last_step = None\n",
    "        self._last_time = None\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "        self.step = step\n",
    "\n",
    "    def scalar(self, name, value):\n",
    "        self._scalars[name] = float(value)\n",
    "\n",
    "    def image(self, name, value):\n",
    "        self._images[name] = np.array(value)\n",
    "\n",
    "    def video(self, name, value):\n",
    "        self._videos[name] = np.array(value)\n",
    "\n",
    "    def write(self, fps=False, step=False):\n",
    "        if not step:\n",
    "            step = self.step\n",
    "        scalars = list(self._scalars.items())\n",
    "        if fps:\n",
    "            scalars.append((\"fps\", self._compute_fps(step)))\n",
    "        print(f\"[{step}]\", \" / \".join(f\"{k} {v:.1f}\" for k, v in scalars))\n",
    "        with (self._logdir / \"metrics.jsonl\").open(\"a\") as f:\n",
    "            f.write(json.dumps({\"step\": step, **dict(scalars)}) + \"\\n\")\n",
    "        for name, value in scalars:\n",
    "            if \"/\" not in name:\n",
    "                self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "            else:\n",
    "                self._writer.add_scalar(name, value, step)\n",
    "        for name, value in self._images.items():\n",
    "            self._writer.add_image(name, value, step)\n",
    "        for name, value in self._videos.items():\n",
    "            name = name if isinstance(name, str) else name.decode(\"utf-8\")\n",
    "            if np.issubdtype(value.dtype, np.floating):\n",
    "                value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "            B, T, H, W, C = value.shape\n",
    "            value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "            self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "        self._writer.flush()\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "\n",
    "    def _compute_fps(self, step):\n",
    "        if self._last_step is None:\n",
    "            self._last_time = time.time()\n",
    "            self._last_step = step\n",
    "            return 0\n",
    "        steps = step - self._last_step\n",
    "        duration = time.time() - self._last_time\n",
    "        self._last_time += duration\n",
    "        self._last_step = step\n",
    "        return steps / duration\n",
    "\n",
    "    def offline_scalar(self, name, value, step):\n",
    "        self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "\n",
    "    def offline_video(self, name, value, step):\n",
    "        if np.issubdtype(value.dtype, np.floating):\n",
    "            value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "        B, T, H, W, C = value.shape\n",
    "        value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "        self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "\n",
    "def simulate(\n",
    "    agent,\n",
    "    envs,\n",
    "    cache,\n",
    "    directory,\n",
    "    logger,\n",
    "    is_eval=False,\n",
    "    limit=None,\n",
    "    steps=0,\n",
    "    episodes=0,\n",
    "    state=None,\n",
    "):\n",
    "    # initialize or unpack simulation state\n",
    "    if state is None:\n",
    "        step, episode = 0, 0\n",
    "        done = np.ones(len(envs), bool)\n",
    "        length = np.zeros(len(envs), np.int32)\n",
    "        obs = [None] * len(envs)\n",
    "        agent_state = None\n",
    "        reward = [0] * len(envs)\n",
    "    else:\n",
    "        step, episode, done, length, obs, agent_state, reward = state\n",
    "    while (steps and step < steps) or (episodes and episode < episodes):\n",
    "        # reset envs if necessary\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            results = [envs[i].reset() for i in indices]\n",
    "            results = [r() for r in results]\n",
    "            for index, result in zip(indices, results):\n",
    "                # Handle gymnasium's (obs, info) return format\n",
    "                if isinstance(result, tuple):\n",
    "                    result = result[0]\n",
    "                t = result.copy()\n",
    "                t = {k: convert(v) for k, v in t.items()}\n",
    "                # action will be added to transition in add_to_cache\n",
    "                t[\"reward\"] = 0.0\n",
    "                t[\"discount\"] = 1.0\n",
    "                # initial state should be added to cache\n",
    "                add_to_cache(cache, envs[index].id, t)\n",
    "                # replace obs with done by initial state\n",
    "                obs[index] = result\n",
    "        # step agents\n",
    "        obs = {k: np.stack([o[k] for o in obs]) for k in obs[0] if \"log_\" not in k}\n",
    "        action, agent_state = agent(obs, done, agent_state)\n",
    "        if isinstance(action, dict):\n",
    "            action = [\n",
    "                {k: np.array(action[k][i].detach().cpu()) for k in action}\n",
    "                for i in range(len(envs))\n",
    "            ]\n",
    "        else:\n",
    "            action = np.array(action)\n",
    "        assert len(action) == len(envs)\n",
    "        # step envs\n",
    "        results = [e.step(a) for e, a in zip(envs, action)]\n",
    "        results = [r() for r in results]\n",
    "        # Handle gymnasium's 5-tuple format (obs, reward, terminated, truncated, info)\n",
    "        obs, reward, terminated, truncated = zip(*[p[:4] for p in results])\n",
    "        done = np.array([t or tr for t, tr in zip(terminated, truncated)])\n",
    "        obs = list(obs)\n",
    "        reward = list(reward)\n",
    "        episode += int(done.sum())\n",
    "        length += 1\n",
    "        step += len(envs)\n",
    "        length *= 1 - done\n",
    "        # add to cache\n",
    "        for a, result, env in zip(action, results, envs):\n",
    "            o, r, term, trunc, info = result\n",
    "            d = term or trunc\n",
    "            o = {k: convert(v) for k, v in o.items()}\n",
    "            transition = o.copy()\n",
    "            if isinstance(a, dict):\n",
    "                transition.update(a)\n",
    "            else:\n",
    "                transition[\"action\"] = a\n",
    "            transition[\"reward\"] = r\n",
    "            transition[\"discount\"] = info.get(\"discount\", np.array(1 - float(d)))\n",
    "            add_to_cache(cache, env.id, transition)\n",
    "\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            # logging for done episode\n",
    "            for i in indices:\n",
    "                save_episodes(directory, {envs[i].id: cache[envs[i].id]})\n",
    "                length = len(cache[envs[i].id][\"reward\"]) - 1\n",
    "                score = float(np.array(cache[envs[i].id][\"reward\"]).sum())\n",
    "                video = cache[envs[i].id][\"image\"]\n",
    "                # record logs given from environments\n",
    "                for key in list(cache[envs[i].id].keys()):\n",
    "                    if \"log_\" in key:\n",
    "                        logger.scalar(\n",
    "                            key, float(np.array(cache[envs[i].id][key]).sum())\n",
    "                        )\n",
    "                        # log items won't be used later\n",
    "                        cache[envs[i].id].pop(key)\n",
    "\n",
    "                if not is_eval:\n",
    "                    step_in_dataset = erase_over_episodes(cache, limit)\n",
    "                    logger.scalar(f\"dataset_size\", step_in_dataset)\n",
    "                    logger.scalar(f\"train_return\", score)\n",
    "                    logger.scalar(f\"train_length\", length)\n",
    "                    logger.scalar(f\"train_episodes\", len(cache))\n",
    "                    logger.write(step=logger.step)\n",
    "                else:\n",
    "                    if not \"eval_lengths\" in locals():\n",
    "                        eval_lengths = []\n",
    "                        eval_scores = []\n",
    "                        eval_done = False\n",
    "                    # start counting scores for evaluation\n",
    "                    eval_scores.append(score)\n",
    "                    eval_lengths.append(length)\n",
    "\n",
    "                    score = sum(eval_scores) / len(eval_scores)\n",
    "                    length = sum(eval_lengths) / len(eval_lengths)\n",
    "                    logger.video(f\"eval_policy\", np.array(video)[None])\n",
    "\n",
    "                    if len(eval_scores) >= episodes and not eval_done:\n",
    "                        logger.scalar(f\"eval_return\", score)\n",
    "                        logger.scalar(f\"eval_length\", length)\n",
    "                        logger.scalar(f\"eval_episodes\", len(eval_scores))\n",
    "                        logger.write(step=logger.step)\n",
    "                        eval_done = True\n",
    "    if is_eval:\n",
    "        # keep only last item for saving memory. this cache is used for video_pred later\n",
    "        while len(cache) > 1:\n",
    "            # FIFO\n",
    "            cache.popitem(last=False)\n",
    "    return (step - steps, episode - episodes, done, length, obs, agent_state, reward)\n",
    "\n",
    "\n",
    "def add_to_cache(cache, id, transition):\n",
    "    if id not in cache:\n",
    "        cache[id] = dict()\n",
    "        for key, val in transition.items():\n",
    "            cache[id][key] = [convert(val)]\n",
    "    else:\n",
    "        for key, val in transition.items():\n",
    "            if key not in cache[id]:\n",
    "                # fill missing data(action, etc.) at second time\n",
    "                cache[id][key] = [convert(0 * val)]\n",
    "                cache[id][key].append(convert(val))\n",
    "            else:\n",
    "                cache[id][key].append(convert(val))\n",
    "\n",
    "\n",
    "def erase_over_episodes(cache, dataset_size):\n",
    "    step_in_dataset = 0\n",
    "    for key, ep in reversed(sorted(cache.items(), key=lambda x: x[0])):\n",
    "        if (\n",
    "            not dataset_size\n",
    "            or step_in_dataset + (len(ep[\"reward\"]) - 1) <= dataset_size\n",
    "        ):\n",
    "            step_in_dataset += len(ep[\"reward\"]) - 1\n",
    "        else:\n",
    "            del cache[key]\n",
    "    return step_in_dataset\n",
    "\n",
    "\n",
    "def convert(value, precision=32):\n",
    "    value = np.array(value)\n",
    "    if np.issubdtype(value.dtype, np.floating):\n",
    "        dtype = {16: np.float16, 32: np.float32, 64: np.float64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.signedinteger):\n",
    "        dtype = {16: np.int16, 32: np.int32, 64: np.int64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.uint8):\n",
    "        dtype = np.uint8\n",
    "    elif np.issubdtype(value.dtype, bool):\n",
    "        dtype = bool\n",
    "    else:\n",
    "        raise NotImplementedError(value.dtype)\n",
    "    return value.astype(dtype)\n",
    "\n",
    "\n",
    "def save_episodes(directory, episodes):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    for filename, episode in episodes.items():\n",
    "        length = len(episode[\"reward\"])\n",
    "        filename = directory / f\"{filename}-{length}.npz\"\n",
    "        with io.BytesIO() as f1:\n",
    "            np.savez_compressed(f1, **episode)\n",
    "            f1.seek(0)\n",
    "            with filename.open(\"wb\") as f2:\n",
    "                f2.write(f1.read())\n",
    "    return True\n",
    "\n",
    "def sample_episodes(episodes, length, seed=0):\n",
    "    np_random = np.random.RandomState(seed)\n",
    "    while True:\n",
    "        size = 0\n",
    "        ret = None\n",
    "        p = np.array(\n",
    "            [len(next(iter(episode.values()))) for episode in episodes.values()]\n",
    "        )\n",
    "        p = p / np.sum(p)\n",
    "        while size < length:\n",
    "            episode = np_random.choice(list(episodes.values()), p=p)\n",
    "            total = len(next(iter(episode.values())))\n",
    "            # make sure at least one transition included\n",
    "            if total < 2:\n",
    "                continue\n",
    "            if not ret:\n",
    "                index = int(np_random.randint(0, total - 1))\n",
    "                ret = {\n",
    "                    k: v[index : min(index + length, total)].copy()\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][0] = True\n",
    "            else:\n",
    "                # 'is_first' comes after 'is_last'\n",
    "                index = 0\n",
    "                possible = length - size\n",
    "                ret = {\n",
    "                    k: np.append(\n",
    "                        ret[k], v[index : min(index + possible, total)].copy(), axis=0\n",
    "                    )\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][size] = True\n",
    "            size = len(next(iter(ret.values())))\n",
    "        yield ret\n",
    "\n",
    "\n",
    "def load_episodes(directory, limit=None, reverse=True):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    episodes = collections.OrderedDict()\n",
    "    total = 0\n",
    "    if reverse:\n",
    "        for filename in reversed(sorted(directory.glob(\"*.npz\"))):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            # extract only filename without extension\n",
    "            episodes[str(os.path.splitext(os.path.basename(filename))[0])] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    else:\n",
    "        for filename in sorted(directory.glob(\"*.npz\")):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            episodes[str(filename)] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    return episodes\n",
    "\n",
    "\n",
    "class SampleDist:\n",
    "    def __init__(self, dist, samples=100):\n",
    "        self._dist = dist\n",
    "        self._samples = samples\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"SampleDist\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def mean(self):\n",
    "        samples = self._dist.sample(self._samples)\n",
    "        return torch.mean(samples, 0)\n",
    "\n",
    "    def mode(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self._dist.log_prob(sample)\n",
    "        return sample[torch.argmax(logprob)][0]\n",
    "\n",
    "    def entropy(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self.log_prob(sample)\n",
    "        return -torch.mean(logprob, 0)\n",
    "\n",
    "\n",
    "class OneHotDist(torchd.one_hot_categorical.OneHotCategorical):\n",
    "    def __init__(self, logits=None, probs=None, unimix_ratio=0.0):\n",
    "        if logits is not None and unimix_ratio > 0.0:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs = probs * (1.0 - unimix_ratio) + unimix_ratio / probs.shape[-1]\n",
    "            logits = torch.log(probs)\n",
    "            super().__init__(logits=logits, probs=None)\n",
    "        else:\n",
    "            super().__init__(logits=logits, probs=probs)\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = F.one_hot(\n",
    "            torch.argmax(super().logits, axis=-1), super().logits.shape[-1]\n",
    "        )\n",
    "        return _mode.detach() + super().logits - super().logits.detach()\n",
    "\n",
    "    def sample(self, sample_shape=(), seed=None):\n",
    "        if seed is not None:\n",
    "            raise ValueError(\"need to check\")\n",
    "        sample = super().sample(sample_shape).detach()\n",
    "        probs = super().probs\n",
    "        while len(probs.shape) < len(sample.shape):\n",
    "            probs = probs[None]\n",
    "        sample += probs - probs.detach()\n",
    "        return sample\n",
    "\n",
    "\n",
    "class DiscDist:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logits,\n",
    "        low=-20.0,\n",
    "        high=20.0,\n",
    "        transfwd=symlog,\n",
    "        transbwd=symexp,\n",
    "        device=\"cuda\",\n",
    "    ):\n",
    "        self.logits = logits\n",
    "        self.probs = torch.softmax(logits, -1)\n",
    "        self.buckets = torch.linspace(low, high, steps=255, device=device)\n",
    "        self.width = (self.buckets[-1] - self.buckets[0]) / 255\n",
    "        self.transfwd = transfwd\n",
    "        self.transbwd = transbwd\n",
    "\n",
    "    def mean(self):\n",
    "        _mean = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mean, dim=-1, keepdim=True))\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mode, dim=-1, keepdim=True))\n",
    "\n",
    "    # Inside OneHotCategorical, log_prob is calculated using only max element in targets\n",
    "    def log_prob(self, x):\n",
    "        x = self.transfwd(x)\n",
    "        # x(time, batch, 1)\n",
    "        below = torch.sum((self.buckets <= x[..., None]).to(torch.int32), dim=-1) - 1\n",
    "        above = len(self.buckets) - torch.sum(\n",
    "            (self.buckets > x[..., None]).to(torch.int32), dim=-1\n",
    "        )\n",
    "        # this is implemented using clip at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        below = torch.clip(below, 0, len(self.buckets) - 1)\n",
    "        above = torch.clip(above, 0, len(self.buckets) - 1)\n",
    "        equal = below == above\n",
    "\n",
    "        dist_to_below = torch.where(equal, 1, torch.abs(self.buckets[below] - x))\n",
    "        dist_to_above = torch.where(equal, 1, torch.abs(self.buckets[above] - x))\n",
    "        total = dist_to_below + dist_to_above\n",
    "        weight_below = dist_to_above / total\n",
    "        weight_above = dist_to_below / total\n",
    "        target = (\n",
    "            F.one_hot(below, num_classes=len(self.buckets)) * weight_below[..., None]\n",
    "            + F.one_hot(above, num_classes=len(self.buckets)) * weight_above[..., None]\n",
    "        )\n",
    "        log_pred = self.logits - torch.logsumexp(self.logits, -1, keepdim=True)\n",
    "        target = target.squeeze(-2)\n",
    "\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "    def log_prob_target(self, target):\n",
    "        log_pred = super().logits - torch.logsumexp(super().logits, -1, keepdim=True)\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "\n",
    "class MSEDist:\n",
    "    def __init__(self, mode, agg=\"sum\"):\n",
    "        self._mode = mode\n",
    "        self._agg = agg\n",
    "\n",
    "    def mode(self):\n",
    "        return self._mode\n",
    "\n",
    "    def mean(self):\n",
    "        return self._mode\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape, (self._mode.shape, value.shape)\n",
    "        distance = (self._mode - value) ** 2\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class SymlogDist:\n",
    "    def __init__(self, mode, dist=\"mse\", agg=\"sum\", tol=1e-8):\n",
    "        self._mode = mode\n",
    "        self._dist = dist\n",
    "        self._agg = agg\n",
    "        self._tol = tol\n",
    "\n",
    "    def mode(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def mean(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape\n",
    "        if self._dist == \"mse\":\n",
    "            distance = (self._mode - symlog(value)) ** 2.0\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        elif self._dist == \"abs\":\n",
    "            distance = torch.abs(self._mode - symlog(value))\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        else:\n",
    "            raise NotImplementedError(self._dist)\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class ContDist:\n",
    "    def __init__(self, dist=None, absmax=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "        self.absmax = absmax\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        out = self._dist.mean\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        out = self._dist.rsample(sample_shape)\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return self._dist.log_prob(x)\n",
    "\n",
    "\n",
    "class Bernoulli:\n",
    "    def __init__(self, dist=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = torch.round(self._dist.mean)\n",
    "        return _mode.detach() + self._dist.mean - self._dist.mean.detach()\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        return self._dist.rsample(sample_shape)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        _logits = self._dist.base_dist.logits\n",
    "        log_probs0 = -F.softplus(_logits)\n",
    "        log_probs1 = -F.softplus(-_logits)\n",
    "\n",
    "        return torch.sum(log_probs0 * (1 - x) + log_probs1 * x, -1)\n",
    "\n",
    "\n",
    "class UnnormalizedHuber(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, threshold=1, **kwargs):\n",
    "        super().__init__(loc, scale, **kwargs)\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def log_prob(self, event):\n",
    "        return -(\n",
    "            torch.sqrt((event - self.mean) ** 2 + self._threshold**2) - self._threshold\n",
    "        )\n",
    "\n",
    "    def mode(self):\n",
    "        return self.mean\n",
    "\n",
    "\n",
    "class SafeTruncatedNormal(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, low, high, clip=1e-6, mult=1):\n",
    "        super().__init__(loc, scale)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._clip = clip\n",
    "        self._mult = mult\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        event = super().sample(sample_shape)\n",
    "        if self._clip:\n",
    "            clipped = torch.clip(event, self._low + self._clip, self._high - self._clip)\n",
    "            event = event - event.detach() + clipped.detach()\n",
    "        if self._mult:\n",
    "            event *= self._mult\n",
    "        return event\n",
    "\n",
    "\n",
    "class TanhBijector(torchd.Transform):\n",
    "    def __init__(self, validate_args=False, name=\"tanh\"):\n",
    "        super().__init__()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y = torch.where(\n",
    "            (torch.abs(y) <= 1.0), torch.clamp(y, -0.99999997, 0.99999997), y\n",
    "        )\n",
    "        y = torch.atanh(y)\n",
    "        return y\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        log2 = torch.math.log(2.0)\n",
    "        return 2.0 * (log2 - x - torch.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "def static_scan_for_lambda_return(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    indices = reversed(indices)\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        # (inputs, pcont) -> (inputs[index], pcont[index])\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            outputs = last\n",
    "            flag = False\n",
    "        else:\n",
    "            outputs = torch.cat([outputs, last], dim=-1)\n",
    "    outputs = torch.reshape(outputs, [outputs.shape[0], outputs.shape[1], 1])\n",
    "    outputs = torch.flip(outputs, [1])\n",
    "    outputs = torch.unbind(outputs, dim=0)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def lambda_return(reward, value, pcont, bootstrap, lambda_, axis):\n",
    "    # Setting lambda=1 gives a discounted Monte Carlo return.\n",
    "    # Setting lambda=0 gives a fixed 1-step return.\n",
    "    # assert reward.shape.ndims == value.shape.ndims, (reward.shape, value.shape)\n",
    "    assert len(reward.shape) == len(value.shape), (reward.shape, value.shape)\n",
    "    if isinstance(pcont, (int, float)):\n",
    "        pcont = pcont * torch.ones_like(reward)\n",
    "    dims = list(range(len(reward.shape)))\n",
    "    dims = [axis] + dims[1:axis] + [0] + dims[axis + 1 :]\n",
    "    if axis != 0:\n",
    "        reward = reward.permute(dims)\n",
    "        value = value.permute(dims)\n",
    "        pcont = pcont.permute(dims)\n",
    "    if bootstrap is None:\n",
    "        bootstrap = torch.zeros_like(value[-1])\n",
    "    next_values = torch.cat([value[1:], bootstrap[None]], 0)\n",
    "    inputs = reward + pcont * next_values * (1 - lambda_)\n",
    "    # returns = static_scan(\n",
    "    #    lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg,\n",
    "    #    (inputs, pcont), bootstrap, reverse=True)\n",
    "    # reimplement to optimize performance\n",
    "    returns = static_scan_for_lambda_return(\n",
    "        lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg, (inputs, pcont), bootstrap\n",
    "    )\n",
    "    if axis != 0:\n",
    "        returns = returns.permute(dims)\n",
    "    return returns\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        parameters,\n",
    "        lr,\n",
    "        eps=1e-4,\n",
    "        clip=None,\n",
    "        wd=None,\n",
    "        wd_pattern=r\".*\",\n",
    "        opt=\"adam\",\n",
    "        use_amp=False,\n",
    "    ):\n",
    "        assert 0 <= wd < 1\n",
    "        assert not clip or 1 <= clip\n",
    "        self._name = name\n",
    "        self._parameters = parameters\n",
    "        self._clip = clip\n",
    "        self._wd = wd\n",
    "        self._wd_pattern = wd_pattern\n",
    "        self._opt = {\n",
    "            \"adam\": lambda: torch.optim.Adam(parameters, lr=lr, eps=eps),\n",
    "            \"nadam\": lambda: NotImplemented(f\"{opt} is not implemented\"),\n",
    "            \"adamax\": lambda: torch.optim.Adamax(parameters, lr=lr, eps=eps),\n",
    "            \"sgd\": lambda: torch.optim.SGD(parameters, lr=lr),\n",
    "            \"momentum\": lambda: torch.optim.SGD(parameters, lr=lr, momentum=0.9),\n",
    "        }[opt]()\n",
    "        self._scaler = torch.amp.GradScaler(device='cuda', enabled=use_amp)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            \"opt\": self._opt.state_dict(),\n",
    "            \"scaler\": self._scaler.state_dict(),\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state):\n",
    "        self._opt.load_state_dict(state[\"opt\"])\n",
    "        self._scaler.load_state_dict(state[\"scaler\"])\n",
    "        \n",
    "    def __call__(self, loss, params, retain_graph=True):\n",
    "        assert len(loss.shape) == 0, loss.shape\n",
    "        metrics = {}\n",
    "        metrics[f\"{self._name}_loss\"] = loss.detach().cpu().numpy()\n",
    "        self._opt.zero_grad()\n",
    "        self._scaler.scale(loss).backward(retain_graph=retain_graph)\n",
    "        self._scaler.unscale_(self._opt)\n",
    "        # loss.backward(retain_graph=retain_graph)\n",
    "        norm = torch.nn.utils.clip_grad_norm_(params, self._clip)\n",
    "        if self._wd:\n",
    "            self._apply_weight_decay(params)\n",
    "        self._scaler.step(self._opt)\n",
    "        self._scaler.update()\n",
    "        # self._opt.step()\n",
    "        self._opt.zero_grad()\n",
    "        metrics[f\"{self._name}_grad_norm\"] = to_np(norm)\n",
    "        return metrics\n",
    "\n",
    "    def _apply_weight_decay(self, varibs):\n",
    "        nontrivial = self._wd_pattern != r\".*\"\n",
    "        if nontrivial:\n",
    "            raise NotImplementedError\n",
    "        for var in varibs:\n",
    "            var.data = (1 - self._wd) * var.data\n",
    "\n",
    "\n",
    "def args_type(default):\n",
    "    def parse_string(x):\n",
    "        if default is None:\n",
    "            return x\n",
    "        if isinstance(default, bool):\n",
    "            return bool([\"False\", \"True\"].index(x))\n",
    "        if isinstance(default, int):\n",
    "            return float(x) if (\"e\" in x or \".\" in x) else int(x)\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(args_type(default[0])(y) for y in x.split(\",\"))\n",
    "        return type(default)(x)\n",
    "\n",
    "    def parse_object(x):\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(x)\n",
    "        return x\n",
    "\n",
    "    return lambda x: parse_string(x) if isinstance(x, str) else parse_object(x)\n",
    "\n",
    "\n",
    "def static_scan(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            if type(last) == type({}):\n",
    "                outputs = {\n",
    "                    key: value.clone().unsqueeze(0) for key, value in last.items()\n",
    "                }\n",
    "            else:\n",
    "                outputs = []\n",
    "                for _last in last:\n",
    "                    if type(_last) == type({}):\n",
    "                        outputs.append(\n",
    "                            {\n",
    "                                key: value.clone().unsqueeze(0)\n",
    "                                for key, value in _last.items()\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        outputs.append(_last.clone().unsqueeze(0))\n",
    "            flag = False\n",
    "        else:\n",
    "            if type(last) == type({}):\n",
    "                for key in last.keys():\n",
    "                    outputs[key] = torch.cat(\n",
    "                        [outputs[key], last[key].unsqueeze(0)], dim=0\n",
    "                    )\n",
    "            else:\n",
    "                for j in range(len(outputs)):\n",
    "                    if type(last[j]) == type({}):\n",
    "                        for key in last[j].keys():\n",
    "                            outputs[j][key] = torch.cat(\n",
    "                                [outputs[j][key], last[j][key].unsqueeze(0)], dim=0\n",
    "                            )\n",
    "                    else:\n",
    "                        outputs[j] = torch.cat(\n",
    "                            [outputs[j], last[j].unsqueeze(0)], dim=0\n",
    "                        )\n",
    "    if type(last) == type({}):\n",
    "        outputs = [outputs]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class Every:\n",
    "    def __init__(self, every):\n",
    "        self._every = every\n",
    "        self._last = None\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._every:\n",
    "            return 0\n",
    "        if self._last is None:\n",
    "            self._last = step\n",
    "            return 1\n",
    "        count = int((step - self._last) / self._every)\n",
    "        self._last += self._every * count\n",
    "        return count\n",
    "\n",
    "\n",
    "class Once:\n",
    "    def __init__(self):\n",
    "        self._once = True\n",
    "\n",
    "    def __call__(self):\n",
    "        if self._once:\n",
    "            self._once = False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Until:\n",
    "    def __init__(self, until):\n",
    "        self._until = until\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._until:\n",
    "            return True\n",
    "        return step < self._until\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        in_num = m.in_features\n",
    "        out_num = m.out_features\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        space = m.kernel_size[0] * m.kernel_size[1]\n",
    "        in_num = space * m.in_channels\n",
    "        out_num = space * m.out_channels\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def uniform_weight_init(given_scale):\n",
    "    def f(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            in_num = m.in_features\n",
    "            out_num = m.out_features\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            space = m.kernel_size[0] * m.kernel_size[1]\n",
    "            in_num = space * m.in_channels\n",
    "            out_num = space * m.out_channels\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            m.weight.data.fill_(1.0)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def tensorstats(tensor, prefix=None):\n",
    "    metrics = {\n",
    "        \"mean\": to_np(torch.mean(tensor)),\n",
    "        \"std\": to_np(torch.std(tensor)),\n",
    "        \"min\": to_np(torch.min(tensor)),\n",
    "        \"max\": to_np(torch.max(tensor)),\n",
    "    }\n",
    "    if prefix:\n",
    "        metrics = {f\"{prefix}_{k}\": v for k, v in metrics.items()}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def set_seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def enable_deterministic_run():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def recursively_collect_optim_state_dict(\n",
    "    obj, path=\"\", optimizers_state_dicts=None, visited=None\n",
    "):\n",
    "    if optimizers_state_dicts is None:\n",
    "        optimizers_state_dicts = {}\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    # avoid cyclic reference\n",
    "    if id(obj) in visited:\n",
    "        return optimizers_state_dicts\n",
    "    else:\n",
    "        visited.add(id(obj))\n",
    "    attrs = obj.__dict__\n",
    "    if isinstance(obj, torch.nn.Module):\n",
    "        attrs.update(\n",
    "            {k: attr for k, attr in obj.named_modules() if \".\" not in k and obj != attr}\n",
    "        )\n",
    "    for name, attr in attrs.items():\n",
    "        new_path = path + \".\" + name if path else name\n",
    "        if isinstance(attr, torch.optim.Optimizer):\n",
    "            optimizers_state_dicts[new_path] = attr.state_dict()\n",
    "        elif hasattr(attr, \"__dict__\"):\n",
    "            optimizers_state_dicts.update(\n",
    "                recursively_collect_optim_state_dict(\n",
    "                    attr, new_path, optimizers_state_dicts, visited\n",
    "                )\n",
    "            )\n",
    "    return optimizers_state_dicts\n",
    "\n",
    "\n",
    "def recursively_load_optim_state_dict(obj, optimizers_state_dicts):\n",
    "    for path, state_dict in optimizers_state_dicts.items():\n",
    "        keys = path.split(\".\")\n",
    "        obj_now = obj\n",
    "        for key in keys:\n",
    "            obj_now = getattr(obj_now, key)\n",
    "        obj_now.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1aea588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:31.343183Z",
     "iopub.status.busy": "2026-01-02T05:23:31.342220Z",
     "iopub.status.idle": "2026-01-02T05:23:31.364956Z",
     "shell.execute_reply": "2026-01-02T05:23:31.364449Z"
    },
    "papermill": {
     "duration": 0.074319,
     "end_time": "2026-01-02T05:23:31.366548",
     "exception": false,
     "start_time": "2026-01-02T05:23:31.292229",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "from ActorCritic import MLP\n",
    "from RSSM import RSSM\n",
    "# import tools\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "class RewardEMA:\n",
    "    \"\"\"running mean and std\"\"\"\n",
    "\n",
    "    def __init__(self, device, alpha=1e-2):\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.range = torch.tensor([0.05, 0.95], device=device)\n",
    "\n",
    "    def __call__(self, x, ema_vals):\n",
    "        flat_x = torch.flatten(x.detach())\n",
    "        x_quantile = torch.quantile(input=flat_x, q=self.range)\n",
    "        # this should be in-place operation\n",
    "        ema_vals[:] = self.alpha * x_quantile + (1 - self.alpha) * ema_vals\n",
    "        scale = torch.clip(ema_vals[1] - ema_vals[0], min=1.0)\n",
    "        offset = ema_vals[0]\n",
    "        return offset.detach(), scale.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfaa8b",
   "metadata": {
    "papermill": {
     "duration": 0.0492,
     "end_time": "2026-01-02T05:23:31.465453",
     "exception": false,
     "start_time": "2026-01-02T05:23:31.416253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Frozen Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7befa06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:31.564728Z",
     "iopub.status.busy": "2026-01-02T05:23:31.564410Z",
     "iopub.status.idle": "2026-01-02T05:23:39.882472Z",
     "shell.execute_reply": "2026-01-02T05:23:39.881859Z"
    },
    "papermill": {
     "duration": 8.369825,
     "end_time": "2026-01-02T05:23:39.884194",
     "exception": false,
     "start_time": "2026-01-02T05:23:31.514369",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from click import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ROOT_DIR = Path.cwd().parent # HanoiWorld's parent\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "JEPA_DIR = Path.cwd().parent / \"JEPA\"\n",
    "sys.path.append(str(JEPA_DIR))\n",
    "# from JEPA.jepa_encoder import JEPA_Encoder\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load environment variables\n",
    "# --------------------------------------------------\n",
    "load_dotenv()  # loads .env from project root if present\n",
    "\n",
    "CKPT_ROOT = os.getenv(\"JEPA_CKPT_ROOT\")\n",
    "\n",
    "if CKPT_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        \"JEPA_CKPT_ROOT is not set. \"\n",
    "        \"Please define it in .env or environment variables.\"\n",
    "    )\n",
    "\n",
    "class LatentExpander(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensures world_latent has expected semantic dimension.\n",
    "    Identity if already correct.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, expected_dim: int):\n",
    "        super().__init__()\n",
    "        self.expected_dim = expected_dim\n",
    "        self.proj = None  # lazy init\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        z: [B, T, D] or [B, D]\n",
    "        returns: [B, T, expected_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # Normalize shape\n",
    "        if z.ndim == 2:\n",
    "            z = z.unsqueeze(1)  # [B, 1, D]\n",
    "\n",
    "        assert z.ndim == 3, f\"Expected [B,T,D], got {z.shape}\"\n",
    "\n",
    "        B, T, D = z.shape\n",
    "\n",
    "        # Identity path\n",
    "        if D == self.expected_dim:\n",
    "            return z\n",
    "\n",
    "        # Projection path (lazy, explicit)\n",
    "        if self.proj is None or self.proj.in_features != D:\n",
    "            self.proj = nn.Linear(D, self.expected_dim).to(z.device)\n",
    "\n",
    "        return self.proj(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba391131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:39.985276Z",
     "iopub.status.busy": "2026-01-02T05:23:39.984673Z",
     "iopub.status.idle": "2026-01-02T05:23:41.042165Z",
     "shell.execute_reply": "2026-01-02T05:23:41.041551Z"
    },
    "papermill": {
     "duration": 1.109729,
     "end_time": "2026-01-02T05:23:41.043949",
     "exception": false,
     "start_time": "2026-01-02T05:23:39.934220",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/WorldModel-Self-Driving-Car/JEPA\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/WorldModel-Self-Driving-Car/JEPA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from transformers import AutoModel\n",
    "\n",
    "from JEPA_PrimitiveLayer.vjepa.model import PrimitiveLayerJEPA\n",
    "# from JEPA.latent_expander import LatentExpander   # adjust import if needed\n",
    "\n",
    "\n",
    "class FrozenJEPA1VisionEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Unified Frozen JEPA-1 Vision Encoder\n",
    "\n",
    "    ✔ Loads V-JEPA2 ViT-L backbone internally\n",
    "    ✔ Uses PrimitiveLayerJEPA only\n",
    "    ✔ Fully frozen (eval-only)\n",
    "    ✔ Handles single-frame & temporal inputs\n",
    "    ✔ Normalizes and reshapes inputs safely\n",
    "    ✔ RSSM-safe latent output\n",
    "\n",
    "    Output:\n",
    "        - [B, D]        single frame\n",
    "        - [B, T, D]     temporal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_dim: int = 128,\n",
    "        device=None,\n",
    "        ckpt_root=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device if device is not None else torch.device(\"cpu\")\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Vision backbone (must match JEPA-1 training)\n",
    "        # --------------------------------------------------\n",
    "        backbone = AutoModel.from_pretrained(\n",
    "            \"facebook/vjepa2-vitl-fpc64-256\",\n",
    "            torch_dtype=torch.float16,\n",
    "        )\n",
    "        backbone.to(self.device)\n",
    "        backbone.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        for p in backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        vision_encoder = backbone.encoder\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # JEPA-1 Primitive Layer\n",
    "        # --------------------------------------------------\n",
    "        self.jepa1 = PrimitiveLayerJEPA(\n",
    "            encoder=vision_encoder,\n",
    "            grid_h=16,\n",
    "            grid_w=16,\n",
    "            enc_dim=1024,\n",
    "            prim_dim=out_dim,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Load JEPA-1 checkpoint (optional but recommended)\n",
    "        # --------------------------------------------------\n",
    "        if ckpt_root is not None:\n",
    "            self._load_checkpoint_jepa1(ckpt_root)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # RSSM safety\n",
    "        # --------------------------------------------------\n",
    "        self.latent_expander = LatentExpander(expected_dim=out_dim)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Freeze everything\n",
    "        # --------------------------------------------------\n",
    "        self.eval()\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    # ======================================================\n",
    "    # Checkpoint loader\n",
    "    # ======================================================\n",
    "    def _load_checkpoint_jepa1(self, root):\n",
    "        root = Path(root)\n",
    "        assert root.exists(), f\"JEPA ckpt root not found: {root}\"\n",
    "\n",
    "        ckpt = torch.load(root / \"jepa1_final.pt\", map_location=\"cpu\")\n",
    "        self.jepa1.load_state_dict(ckpt[\"state\"], strict=False)\n",
    "\n",
    "        print(\"✅ Loaded JEPA-1 checkpoint\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Forward\n",
    "    # ======================================================\n",
    "    @torch.no_grad()\n",
    "    def forward(self, pixel_values):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pixel_values:\n",
    "                [B,H,W,3]\n",
    "                [B,T,H,W,3]\n",
    "                [B,3,T,H,W]\n",
    "                [B,C,H,W]\n",
    "                [B,T,C,H,W]\n",
    "\n",
    "        Returns:\n",
    "            embed:\n",
    "                [B, D]      single-frame\n",
    "                [B, T, D]   temporal\n",
    "        \"\"\"\n",
    "\n",
    "        x = pixel_values\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Normalize uint8\n",
    "        # ----------------------------------\n",
    "        if x.dtype == torch.uint8:\n",
    "            x = x.float() / 255.0\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Canonicalize shape\n",
    "        # ----------------------------------\n",
    "        if x.ndim == 4:\n",
    "            # [B,H,W,3] or [B,C,H,W]\n",
    "            if x.shape[-1] == 3:\n",
    "                x = x.permute(0, 3, 1, 2)   # → [B,3,H,W]\n",
    "            x = x.unsqueeze(1)              # → [B,1,3,H,W]\n",
    "\n",
    "        elif x.ndim == 5:\n",
    "            # [B,T,H,W,3]\n",
    "            if x.shape[-1] == 3:\n",
    "                x = x.permute(0, 1, 4, 2, 3)  # → [B,T,3,H,W]\n",
    "            # [B,3,T,H,W]\n",
    "            elif x.shape[1] == 3:\n",
    "                x = x.permute(0, 2, 1, 3, 4)  # → [B,T,3,H,W]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input shape: {x.shape}\")\n",
    "\n",
    "        B, T, C, H, W = x.shape\n",
    "        assert C == 3, f\"Expected 3 channels, got {C}\"\n",
    "\n",
    "        # ----------------------------------\n",
    "        # JEPA-1 forward\n",
    "        # ----------------------------------\n",
    "        # x = x.reshape(B * T, C, H, W)\n",
    "        # print(f\"THE SHAPE of x - debug in FrozenJEPA1VisionEncoder {x.shape}\")\n",
    "        tokens, _ = self.jepa1(x)           # [B*T, N, D] # it's need 5\n",
    "        embed = tokens.mean(dim=1)          # [B*T, D]\n",
    "        embed = embed.view(B, T, -1)        # [B,T,D]\n",
    "        # print(f\"THE SHAPE of embed- debug in FrozenJEPA1VisionEncoder before reshape {embed.shape}\")\n",
    "\n",
    "\n",
    "        # ----------------------------------\n",
    "        # RSSM safety\n",
    "        # ----------------------------------\n",
    "        embed = self.latent_expander(embed)\n",
    "        # print(f\"THE SHAPE of embed 2- debug in FrozenJEPA1VisionEncoder before reshape {embed.shape}\")\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Return shape\n",
    "        # ----------------------------------\n",
    "        # if T == 1:\n",
    "        #     return embed[:, 0]              # [B,D]\n",
    "        # print(f\"THE SHAPE of embed 3- debug in FrozenJEPA1VisionEncoder before reshape {embed.shape}\")\n",
    "\n",
    "        return embed                         # [B,T,D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7607affd",
   "metadata": {
    "papermill": {
     "duration": 0.047608,
     "end_time": "2026-01-02T05:23:41.140510",
     "exception": false,
     "start_time": "2026-01-02T05:23:41.092902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d92018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:41.238903Z",
     "iopub.status.busy": "2026-01-02T05:23:41.237883Z",
     "iopub.status.idle": "2026-01-02T05:23:44.831202Z",
     "shell.execute_reply": "2026-01-02T05:23:44.830344Z"
    },
    "papermill": {
     "duration": 3.644533,
     "end_time": "2026-01-02T05:23:44.832819",
     "exception": false,
     "start_time": "2026-01-02T05:23:41.188286",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/WorldModel-Self-Driving-Car/HanoiWorld\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "env_name=\"roundabout\" # merge, roundabout\n",
    "args = SimpleNamespace(\n",
    "    config=env_name,\n",
    "    steps=10000,                 # e.g. 500_000\n",
    "    logdir=\"runs/rssm_jepa\",\n",
    "    # embed_dim=128,\n",
    "    device=None,                # \"cuda\", \"cpu\", \"mps\" or None (auto)\n",
    ")\n",
    "\n",
    "%cd /kaggle/working/WorldModel-Self-Driving-Car/HanoiWorld\n",
    "from comet_ml import Experiment\n",
    "import argparse\n",
    "import pathlib\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from evaluate import load_config, make_env  # reuse helpers\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "CKPT_ROOT = os.getenv(\"JEPA_CKPT_ROOT\")\n",
    "\n",
    "\n",
    "# train on highway\n",
    "\n",
    "\n",
    "\n",
    "if CKPT_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        \"JEPA_CKPT_ROOT is not set. \"\n",
    "        \"Please define it in .env or environment variables.\"\n",
    "    )\n",
    "\n",
    "# Load config and set runtime overrides.\n",
    "cfg = load_config([args.config])\n",
    "if args.steps is not None:\n",
    "    cfg.steps = args.steps\n",
    "cfg.logdir = pathlib.Path(args.logdir)\n",
    "cfg.logdir.mkdir(parents=True, exist_ok=True)\n",
    "if torch.cuda.is_available():\n",
    "    cfg.device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    cfg.device = torch.device(\"mps\")\n",
    "else:\n",
    "    cfg.device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {cfg.device}\")\n",
    "cfg.embed = 128\n",
    "# Environment.\n",
    "env = make_env(cfg)\n",
    "\n",
    "acts = env.action_space\n",
    "if hasattr(acts, \"n\"):\n",
    "    cfg.num_actions = acts.n\n",
    "elif hasattr(acts, \"shape\"):\n",
    "    cfg.num_actions = int(np.prod(acts.shape))\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported action space: {acts}\")\n",
    "\n",
    "\n",
    "env = make_env(cfg)\n",
    "\n",
    "acts = env.action_space\n",
    "if hasattr(acts, \"n\"):\n",
    "    cfg.num_actions = acts.n\n",
    "elif hasattr(acts, \"shape\"):\n",
    "    cfg.num_actions = int(np.prod(acts.shape))\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported action space: {acts}\")\n",
    "\n",
    "cfg.traj_len = 8  # use 8 or whatever history length you want\n",
    "cfg.graph_nodes = 64\n",
    "cfg.graph_feat  = 13\n",
    "# Default trajectory and graph sizes\n",
    "cfg.traj_len     = getattr(cfg, \"traj_len\", 8)\n",
    "cfg.graph_nodes  = getattr(cfg, \"graph_nodes\", 13)   # adjust to your graph builder\n",
    "# cfg.graph_feat   = getattr(cfg, \"graph_feat\", 13)      # adjust to your graph builder\n",
    "# Replay buffer stored as episodes (OrderedDict of arrays).\n",
    "CKPT_ROOT = os.getenv(\"JEPA_CKPT_ROOT\")\n",
    "logger = Logger(cfg.logdir, step=0)\n",
    "cfg.prefill=2500\n",
    "cfg.dataset_size=20000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51707503",
   "metadata": {
    "papermill": {
     "duration": 0.049442,
     "end_time": "2026-01-02T05:23:44.932449",
     "exception": false,
     "start_time": "2026-01-02T05:23:44.883007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HanoiWorldJepa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a007ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.034557Z",
     "iopub.status.busy": "2026-01-02T05:23:45.034240Z",
     "iopub.status.idle": "2026-01-02T05:23:45.076843Z",
     "shell.execute_reply": "2026-01-02T05:23:45.076228Z"
    },
    "papermill": {
     "duration": 0.095635,
     "end_time": "2026-01-02T05:23:45.078368",
     "exception": false,
     "start_time": "2026-01-02T05:23:44.982733",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "# import tools\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "class HanoiWorldJEPA1(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DreamerV3-style World Model (encoder lives outside).\n",
    "    Components:\n",
    "      - RSSM (dynamics)\n",
    "      - Heads: actor, value, reward, cont\n",
    "      - Optimizers: model_opt, actor_opt, value_opt\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Init\n",
    "    # -----------------------------\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.cfg = config\n",
    "        self.device = config.device\n",
    "        self.use_amp = (getattr(config, \"precision\", 32) == 16)\n",
    "\n",
    "        # 1) Sizes\n",
    "        self.feat_size = self._compute_feat_size(config)\n",
    "\n",
    "        # 2) Modules\n",
    "        self.actor = self._build_actor()\n",
    "        self.value = self._build_value()\n",
    "        self.reward = self._build_reward()\n",
    "        self.cont = self._build_cont()\n",
    "        self.rssm = self._build_rssm()\n",
    "\n",
    "        # 3) Slow target value (optional)\n",
    "        self.slow_value = copy.deepcopy(self.value) if config.critic[\"slow_target\"] else None\n",
    "        self.value_updates = 0\n",
    "        self._use_amp = True if getattr(config, \"precision\", 32) == 16 else False\n",
    "        \n",
    "\n",
    "        # 4) Reward EMA (optional)\n",
    "        if getattr(self.cfg, \"reward_EMA\", False):\n",
    "            self.register_buffer(\"ema_vals\", torch.zeros((2,), device=self.device))\n",
    "            self.reward_ema = RewardEMA(device=self.device)\n",
    "\n",
    "        # 5) Loss scales\n",
    "        self.loss_scales = {\n",
    "            \"reward\": config.reward_head[\"loss_scale\"],\n",
    "            \"cont\": config.cont_head[\"loss_scale\"],\n",
    "        }\n",
    "\n",
    "        # 6) Optimizers\n",
    "        self.model_opt, self.actor_opt, self.value_opt = self._build_optimizers()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Builders\n",
    "    # -----------------------------\n",
    "    def _compute_feat_size(self, cfg):\n",
    "        if cfg.dyn_discrete:\n",
    "            return cfg.dyn_stoch * cfg.dyn_discrete + cfg.dyn_deter\n",
    "        return cfg.dyn_stoch + cfg.dyn_deter\n",
    "\n",
    "    def _model_params(self):\n",
    "        return (\n",
    "            list(self.rssm.parameters())\n",
    "            + list(self.reward.parameters())\n",
    "            + list(self.cont.parameters())\n",
    "        )\n",
    "\n",
    "    def to_time_major(self, x):\n",
    "        # [B, T, ...] → [T, B, ...]\n",
    "        return x.transpose(0, 1).contiguous()\n",
    "        \n",
    "    def _build_actor(self):\n",
    "        c = self.cfg\n",
    "        return MLP(\n",
    "            inp_dim=self.feat_size,\n",
    "            shape=(c.num_actions,),\n",
    "            layers=c.actor[\"layers\"],\n",
    "            units=c.units,\n",
    "            act=c.act,\n",
    "            norm=c.norm,\n",
    "            dist=c.actor[\"dist\"],\n",
    "            std=c.actor[\"std\"],\n",
    "            min_std=c.actor[\"min_std\"],\n",
    "            max_std=c.actor[\"max_std\"],\n",
    "            absmax=1.0,\n",
    "            temp=c.actor[\"temp\"],\n",
    "            unimix_ratio=c.actor[\"unimix_ratio\"],\n",
    "            outscale=c.actor[\"outscale\"],\n",
    "            name=\"Actor\",\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _build_value(self):\n",
    "        c = self.cfg\n",
    "        return MLP(\n",
    "            inp_dim=self.feat_size,\n",
    "            shape=(255,) if c.critic[\"dist\"] == \"symlog_disc\" else (),\n",
    "            layers=c.critic[\"layers\"],\n",
    "            units=c.units,\n",
    "            act=c.act,\n",
    "            norm=c.norm,\n",
    "            dist=c.critic[\"dist\"],\n",
    "            outscale=c.critic[\"outscale\"],\n",
    "            device=self.device,\n",
    "            name=\"Value\",\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _build_reward(self):\n",
    "        c = self.cfg\n",
    "        return MLP(\n",
    "            inp_dim=self.feat_size,\n",
    "            shape=(255,) if c.reward_head[\"dist\"] == \"symlog_disc\" else (),\n",
    "            layers=c.reward_head[\"layers\"],\n",
    "            units=c.units,\n",
    "            act=c.act,\n",
    "            norm=c.norm,\n",
    "            dist=c.reward_head[\"dist\"],\n",
    "            outscale=c.reward_head[\"outscale\"],\n",
    "            device=self.device,\n",
    "            name=\"Reward\",\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _build_cont(self):\n",
    "        c = self.cfg\n",
    "        return MLP(\n",
    "            inp_dim=self.feat_size,\n",
    "            shape=(),\n",
    "            layers=c.cont_head[\"layers\"],\n",
    "            units=c.units,\n",
    "            act=c.act,\n",
    "            norm=c.norm,\n",
    "            dist=\"binary\",\n",
    "            outscale=c.cont_head[\"outscale\"],\n",
    "            device=self.device,\n",
    "            name=\"Cont\",\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _build_rssm(self):\n",
    "        c = self.cfg\n",
    "        return RSSM(\n",
    "            stoch=c.dyn_stoch,\n",
    "            deter=c.dyn_deter,\n",
    "            hidden=c.units,\n",
    "            rec_depth=c.dyn_rec_depth,\n",
    "            discrete=c.dyn_discrete,\n",
    "            num_actions=c.num_actions,\n",
    "            embed=c.embed,      # encoder supplies this externally\n",
    "            device=self.device,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _build_optimizers(self):\n",
    "        c = self.cfg\n",
    "\n",
    "        model_opt = Optimizer(\n",
    "            \"model\",\n",
    "            self._model_params(),\n",
    "            c.model_lr,\n",
    "            c.opt_eps,\n",
    "            c.grad_clip,\n",
    "            c.weight_decay,\n",
    "            opt=c.opt,\n",
    "            use_amp=self._use_amp,\n",
    "        )\n",
    "\n",
    "        kw = dict(wd=c.weight_decay, opt=c.opt, use_amp=self.use_amp)\n",
    "\n",
    "        actor_opt =  Optimizer(\n",
    "            \"actor\",\n",
    "            self.actor.parameters(),\n",
    "            c.actor[\"lr\"],\n",
    "            c.actor[\"eps\"],\n",
    "            c.actor[\"grad_clip\"],\n",
    "            **kw,\n",
    "        )\n",
    "\n",
    "        value_opt = Optimizer(\n",
    "            \"value\",\n",
    "            self.value.parameters(),\n",
    "            c.critic[\"lr\"],\n",
    "            c.critic[\"eps\"],\n",
    "            c.critic[\"grad_clip\"],\n",
    "            **kw,\n",
    "        )\n",
    "\n",
    "        return model_opt, actor_opt, value_opt\n",
    "\n",
    "    # -----------------------------\n",
    "    # Public helpers / API\n",
    "    # -----------------------------\n",
    "    def model_parameters(self):\n",
    "        return list(self.rssm.parameters()) + list(self.reward.parameters()) + list(self.cont.parameters())\n",
    "\n",
    "    def initial_state(self, batch_size=1):\n",
    "        return self.rssm.initial(batch_size)\n",
    "\n",
    "    def get_feat(self, state):\n",
    "        return self.rssm.get_feat(state)\n",
    "\n",
    "    def update_slow_value(self):\n",
    "        \"\"\"Dreamer slow target update schedule (same logic as your code).\"\"\"\n",
    "        c = self.cfg\n",
    "        if self.slow_value is None:\n",
    "            return\n",
    "        if self.value_updates % c.critic[\"slow_target_update\"] == 0:\n",
    "            mix = c.critic[\"slow_target_fraction\"]\n",
    "            for s, d in zip(self.value.parameters(), self.slow_value.parameters()):\n",
    "                d.data = mix * s.data + (1 - mix) * d.data\n",
    "        self.value_updates += 1\n",
    "\n",
    "    # -----------------------------\n",
    "    # Preprocess + embed selection\n",
    "    # -----------------------------\n",
    "    # def preprocess(self, batch):\n",
    "    #     # keep original behavior\n",
    "    #     batch = {k: torch.as_tensor(v, device=self.device, dtype=torch.float32) for k, v in batch.items()}\n",
    "    #     if \"discount\" in batch:\n",
    "    #         batch[\"discount\"] *= self.cfg.discount\n",
    "    #         batch[\"discount\"] = batch[\"discount\"].unsqueeze(-1)\n",
    "    #     assert \"is_first\" in batch and \"is_terminal\" in batch\n",
    "    #     batch[\"cont\"] = (1.0 - batch[\"is_terminal\"]).unsqueeze(-1)\n",
    "    #     return batch\n",
    "\n",
    "    def preprocess(self, batch):\n",
    "        batch = {k: torch.as_tensor(v, device=self.device) for k, v in batch.items()}\n",
    "    \n",
    "        # keep float32 for continuous, but don't force everything blindly\n",
    "        for k in batch:\n",
    "            if batch[k].dtype in (torch.float16, torch.float32, torch.float64):\n",
    "                batch[k] = batch[k].float()\n",
    "    \n",
    "        # discount is already [B,T,1] from your generator; only reshape if needed\n",
    "        if \"discount\" in batch:\n",
    "            batch[\"discount\"] = batch[\"discount\"] * self.cfg.discount\n",
    "            if batch[\"discount\"].ndim == 2:      # [B,T] -> [B,T,1]\n",
    "                batch[\"discount\"] = batch[\"discount\"].unsqueeze(-1)\n",
    "\n",
    "        assert \"is_first\" in batch and \"is_terminal\" in batch\n",
    "    \n",
    "        if batch[\"is_terminal\"].ndim == 2:       # [B,T] -> [B,T,1]\n",
    "            batch[\"is_terminal\"] = batch[\"is_terminal\"].unsqueeze(-1)\n",
    "    \n",
    "        batch[\"cont\"] = (1.0 - batch[\"is_terminal\"])   # already [B,T,1]\n",
    "        return batch\n",
    "        \n",
    "    def select_embed(self, batch):\n",
    "        for k in (\"embed\", \"state\", \"observation\"):\n",
    "            if k in batch:\n",
    "                return batch[k]\n",
    "        raise KeyError(\"Expected one of: 'embed', 'state', 'observation' in batch.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training: Model step\n",
    "    # -----------------------------\n",
    "    def train_model(self, batch):\n",
    "        \"\"\"\n",
    "        Update RSSM + reward head + cont head.\n",
    "        Returns: post_state, context, metrics\n",
    "        \"\"\"\n",
    "        c = self.cfg\n",
    "        batch = self.preprocess(batch)\n",
    "\n",
    "        with RequiresGrad(self):\n",
    "            with torch.amp.autocast(\n",
    "                device_type=self.device.type,\n",
    "                enabled=self.use_amp and self.device.type == \"cuda\",\n",
    "            ):\n",
    "                embed = self.select_embed(batch)\n",
    "                B = batch[\"action\"].shape[1]\n",
    "                if embed.shape[1] == 1 and B > 1:\n",
    "                    embed = embed.expand(-1, B, -1).contiguous()\n",
    "                # print(\"DEBUG IN HANOI WORLD\")\n",
    "                # print(\"embed:\", batch[\"embed\"].shape)\n",
    "\n",
    "                \n",
    "                embed     = self.to_time_major(embed)          # [T, B, E]\n",
    "                action    = self.to_time_major(batch[\"action\"])  # [T, B, A]\n",
    "                is_first  = self.to_time_major(batch[\"is_first\"])# [T, B, 1]\n",
    "                \n",
    "                # post, prior = self.rssm.observe(embed, batch[\"action\"], batch[\"is_first\"])\n",
    "\n",
    "                # print(f\"THE SHAPE of embed {embed.shape}\")\n",
    "                # print(f\"The Shape of action {action.shape}\")\n",
    "                # print(f\"The Shape of is_first {is_first.shape}\")\n",
    "                \n",
    "                post, prior = self.rssm.observe(embed, action, is_first)\n",
    "                # print(\"deter:\", prior[\"deter\"].shape)\n",
    "\n",
    "                kl_loss, kl_value, dyn_loss, rep_loss = self.rssm.kl_loss(\n",
    "                    post, prior, c.kl_free, c.dyn_scale, c.rep_scale\n",
    "                )\n",
    "\n",
    "                # print(\"THE LOSS\")\n",
    "                # print(f\"kl_loss {kl_loss}\")\n",
    "                # print(f\"kl_value {kl_value}\")\n",
    "                # print(f\"dyn_loss {dyn_loss}\")\n",
    "                # print(f\"rep_loss {rep_loss}\")\n",
    "\n",
    "                feat = self.rssm.get_feat(post)\n",
    "\n",
    "                preds = {}\n",
    "                for name, head in ((\"reward\", self.reward), (\"cont\", self.cont)):\n",
    "                    head_inp = feat if (name in c.grad_heads) else feat.detach()\n",
    "                    preds[name] = head(head_inp)\n",
    "\n",
    "                # nll = {name: -pred.log_prob(batch[name]) for name, pred in preds.items()}\n",
    "                targets = {name: self.to_time_major(batch[name]) for name in preds}\n",
    "                nll = {name: -pred.log_prob(targets[name]) for name, pred in preds.items()}\n",
    "                \n",
    "                scaled = {k: v * self.loss_scales.get(k, 1.0) for k, v in nll.items()}\n",
    "                model_loss = sum(scaled.values()) + kl_loss\n",
    "\n",
    "            opt_metrics = self.model_opt(torch.mean(model_loss), self.model_parameters())\n",
    "\n",
    "        metrics = dict(opt_metrics)\n",
    "        metrics.update({f\"{k}_loss\": to_np(v) for k, v in nll.items()})\n",
    "        metrics.update({\n",
    "            \"kl_free\": c.kl_free,\n",
    "            \"dyn_scale\": c.dyn_scale,\n",
    "            \"rep_scale\": c.rep_scale,\n",
    "            \"dyn_loss\": to_np(dyn_loss),\n",
    "            \"rep_loss\": to_np(rep_loss),\n",
    "            \"kl\": to_np(torch.mean(kl_value)),\n",
    "        })\n",
    "\n",
    "        with torch.amp.autocast(\n",
    "            device_type=self.device.type,\n",
    "            enabled=self.use_amp and self.device.type == \"cuda\",\n",
    "        ):\n",
    "            metrics[\"prior_ent\"] = to_np(torch.mean(self.rssm.get_dist(prior).entropy()))\n",
    "            metrics[\"post_ent\"] = to_np(torch.mean(self.rssm.get_dist(post).entropy()))\n",
    "            context = {\n",
    "                \"embed\": embed,\n",
    "                \"feat\": self.rssm.get_feat(post),\n",
    "                \"kl\": kl_value,\n",
    "                \"postent\": self.rssm.get_dist(post).entropy(),\n",
    "            }\n",
    "\n",
    "        post = {k: v.detach() for k, v in post.items()}\n",
    "        return post, context, metrics\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training: Behavior step (actor + value)\n",
    "    # -----------------------------\n",
    "    def train_behavior(self, start, objective):\n",
    "        \"\"\"\n",
    "        Same behavior training as before, but clearly separated.\n",
    "        \"\"\"\n",
    "        self.update_slow_value()\n",
    "        c = self.cfg\n",
    "        metrics = {}\n",
    "\n",
    "        with RequiresGrad(self.actor):\n",
    "            with torch.amp.autocast(\n",
    "                device_type=self.device.type,\n",
    "                enabled=self.use_amp and self.device.type == \"cuda\",\n",
    "            ):\n",
    "                imag_feat, imag_state, imag_action = self._imagine(start, self.actor, c.imag_horizon)\n",
    "                reward = objective(imag_feat, imag_state, imag_action)\n",
    "\n",
    "                actor_ent = self.actor(imag_feat).entropy()\n",
    "                target, weights, base = self._compute_target(imag_feat, imag_state, reward)\n",
    "\n",
    "                actor_loss, mets = self._actor_loss(imag_feat, imag_action, target, weights, base)\n",
    "                actor_loss -= c.actor[\"entropy\"] * actor_ent[:-1, ..., None]\n",
    "                actor_loss = torch.mean(actor_loss)\n",
    "                metrics.update(mets)\n",
    "\n",
    "        with RequiresGrad(self.value):\n",
    "            with torch.amp.autocast(\n",
    "                device_type=self.device.type,\n",
    "                enabled=self.use_amp and self.device.type == \"cuda\",\n",
    "            ):\n",
    "                value = self.value(imag_feat[:-1].detach())\n",
    "                target = torch.stack(target, dim=1)\n",
    "                value_loss = -value.log_prob(target.detach())\n",
    "\n",
    "                if self.slow_value is not None:\n",
    "                    slow_target = self.slow_value(imag_feat[:-1].detach()).mode().detach()\n",
    "                    value_loss -= value.log_prob(slow_target)\n",
    "\n",
    "                value_loss = torch.mean(weights[:-1] * value_loss[:, :, None])\n",
    "\n",
    "        metrics.update(tensorstats(value.mode(), \"value\"))\n",
    "        metrics.update(tensorstats(target, \"target\"))\n",
    "        metrics.update(tensorstats(reward, \"imag_reward\"))\n",
    "\n",
    "        if c.actor[\"dist\"] in [\"onehot\"]:\n",
    "            metrics.update(tensorstats(torch.argmax(imag_action, dim=-1).float(), \"imag_action\"))\n",
    "        else:\n",
    "            metrics.update(tensorstats(imag_action, \"imag_action\"))\n",
    "\n",
    "        with RequiresGrad(self):\n",
    "            metrics.update(self.actor_opt(actor_loss, self.actor.parameters()))\n",
    "            metrics.update(self.value_opt(value_loss, self.value.parameters()))\n",
    "\n",
    "        return imag_feat, imag_state, imag_action, weights, metrics\n",
    "\n",
    "    # -----------------------------\n",
    "    # Imagination + targets (unchanged logic)\n",
    "    # -----------------------------\n",
    "    def _imagine(self, start, policy, horizon):\n",
    "        dynamics = self.rssm\n",
    "        flatten = lambda x: x.reshape([-1] + list(x.shape[2:]))\n",
    "        start = {k: flatten(v) for k, v in start.items()}\n",
    "\n",
    "        def step(prev, _):\n",
    "            state, _, _ = prev\n",
    "            feat = dynamics.get_feat(state)\n",
    "            action = policy(feat.detach()).sample()\n",
    "            succ = dynamics.img_step(state, action)\n",
    "            return succ, feat, action\n",
    "\n",
    "        succ, feats, actions = static_scan(step, [torch.arange(horizon)], (start, None, None))\n",
    "        states = {k: torch.cat([start[k][None], v[:-1]], 0) for k, v in succ.items()}\n",
    "        return feats, states, actions\n",
    "\n",
    "    def _compute_target(self, imag_feat, imag_state, reward):\n",
    "        c = self.cfg\n",
    "        if c.cont_head:\n",
    "            inp = self.rssm.get_feat(imag_state)\n",
    "            discount = c.discount * self.cont(inp).mean\n",
    "        else:\n",
    "            discount = c.discount * torch.ones_like(reward)\n",
    "\n",
    "        value = self.value(imag_feat).mode()\n",
    "        target = lambda_return(\n",
    "            reward[1:], value[:-1], discount[1:], bootstrap=value[-1],\n",
    "            lambda_=c.discount_lambda, axis=0\n",
    "        )\n",
    "        weights = torch.cumprod(torch.cat([torch.ones_like(discount[:1]), discount[:-1]], 0), 0).detach()\n",
    "        return target, weights, value[:-1]\n",
    "\n",
    "    def _actor_loss(self, imag_feat, imag_action, target, weights, base):\n",
    "        c = self.cfg\n",
    "        metrics = {}\n",
    "\n",
    "        policy = self.actor(imag_feat.detach())\n",
    "        target = torch.stack(target, dim=1)\n",
    "\n",
    "        if getattr(c, \"reward_EMA\", False):\n",
    "            offset, scale = self.reward_ema(target, self.ema_vals)\n",
    "            adv = (target - offset) / scale - (base - offset) / scale\n",
    "            metrics[\"EMA_005\"] = to_np(self.ema_vals[0])\n",
    "            metrics[\"EMA_095\"] = to_np(self.ema_vals[1])\n",
    "        else:\n",
    "            adv = target - base\n",
    "\n",
    "        if c.imag_gradient == \"dynamics\":\n",
    "            actor_target = adv\n",
    "        elif c.imag_gradient == \"reinforce\":\n",
    "            actor_target = policy.log_prob(imag_action)[:-1][:, :, None] * (\n",
    "                (target - self.value(imag_feat[:-1]).mode()).detach()\n",
    "            )\n",
    "        elif c.imag_gradient == \"both\":\n",
    "            reinforce = policy.log_prob(imag_action)[:-1][:, :, None] * (\n",
    "                (target - self.value(imag_feat[:-1]).mode()).detach()\n",
    "            )\n",
    "            mix = c.imag_gradient_mix\n",
    "            actor_target = mix * target + (1 - mix) * reinforce\n",
    "            metrics[\"imag_gradient_mix\"] = mix\n",
    "        else:\n",
    "            raise NotImplementedError(c.imag_gradient)\n",
    "\n",
    "        actor_loss = -weights[:-1] * actor_target\n",
    "        return actor_loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a4952",
   "metadata": {
    "papermill": {
     "duration": 0.049454,
     "end_time": "2026-01-02T05:23:45.177910",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.128456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HanoiAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ed4ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.279475Z",
     "iopub.status.busy": "2026-01-02T05:23:45.279066Z",
     "iopub.status.idle": "2026-01-02T05:23:45.293879Z",
     "shell.execute_reply": "2026-01-02T05:23:45.293027Z"
    },
    "papermill": {
     "duration": 0.067211,
     "end_time": "2026-01-02T05:23:45.295294",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.228083",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HanoiAgent(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal JEPA-1 Agent:\n",
    "    - act() for environment interaction\n",
    "    - train() for one gradient update\n",
    "    - exposes latest_losses\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, encoder, world):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.encoder = encoder          # frozen\n",
    "        self.world = world              # RSSM + actor + critic\n",
    "        self.latest_losses = {}\n",
    "\n",
    "    # ====================================================\n",
    "    # Acting (Environment Interaction)\n",
    "    # ====================================================\n",
    "    @torch.no_grad()\n",
    "    def act(self, obs, state=None, training=True):\n",
    "        \"\"\"\n",
    "        obs: dict from env\n",
    "        state: (latent, prev_action) or None\n",
    "        \"\"\"\n",
    "        latent, prev_action = state if state is not None else (None, None)\n",
    "\n",
    "        obs = self._prepare_obs(obs, latent is None)\n",
    "\n",
    "        if prev_action is None:\n",
    "            prev_action = torch.zeros(\n",
    "                obs[\"image\"].shape[0],\n",
    "                self.cfg.num_actions,\n",
    "                device=self.cfg.device,\n",
    "            )\n",
    "\n",
    "        embed = self.encode_step(obs)\n",
    "        obs[\"embed\"] = embed\n",
    "\n",
    "        latent, _ = self.world.rssm.obs_step(\n",
    "            latent, prev_action, embed, obs[\"is_first\"]\n",
    "        )\n",
    "\n",
    "        feat = self.world.get_feat(latent)\n",
    "        actor = self.world.actor(feat)\n",
    "\n",
    "        action = actor.sample() if training else actor.mode()\n",
    "        logprob = actor.log_prob(action)\n",
    "\n",
    "        return (\n",
    "            {\"action\": action, \"logprob\": logprob},\n",
    "            (self._detach(latent), action.detach()),\n",
    "        )\n",
    "\n",
    "    # ====================================================\n",
    "    # Learning (One Update Step)\n",
    "    # ====================================================\n",
    "    def train(self, batch):\n",
    "        \"\"\"\n",
    "        batch: [B,T,...] already prepared by dataset\n",
    "        returns: dict of scalar losses\n",
    "        \"\"\"\n",
    "\n",
    "        assert \"image\" in batch, \"JEPA-1 requires images\"\n",
    "\n",
    "        # Encode sequence once (JEPA-1)\n",
    "        batch[\"embed\"] = self.encode_sequence(batch)\n",
    "\n",
    "        # World model update\n",
    "        post, _, model_metrics = self.world.train_model(batch)\n",
    "\n",
    "        # Behavior learning\n",
    "        reward_fn = lambda f, s, a: self.world.reward(\n",
    "            self.world.get_feat(s)\n",
    "        ).mode()\n",
    "\n",
    "        _, _, _, _, beh_metrics = self.world.train_behavior(post, reward_fn)\n",
    "\n",
    "        # Collect losses\n",
    "        self.latest_losses = self._to_scalars({\n",
    "            **model_metrics,\n",
    "            **beh_metrics,\n",
    "        })\n",
    "\n",
    "        return self.latest_losses\n",
    "\n",
    "    # ====================================================\n",
    "    # Encoders\n",
    "    # ====================================================\n",
    "    def encode_sequence(self, batch):\n",
    "        image = torch.as_tensor(batch[\"image\"], device=self.cfg.device)\n",
    "        if image.dtype == torch.uint8:\n",
    "            image = image.float() / 255.0\n",
    "\n",
    "        image = image.permute(0, 4, 1, 2, 3)  # [B,3,T,H,W]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embed = self.encoder(pixel_values=image)\n",
    "\n",
    "        return embed\n",
    "\n",
    "    def encode_step(self, obs):\n",
    "        image = obs[\"image\"]\n",
    "        if image.dtype == torch.uint8:\n",
    "            image = image.float() / 255.0\n",
    "\n",
    "        image = image.unsqueeze(1).permute(0, 4, 1, 2, 3)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embed = self.encoder(pixel_values=image)\n",
    "\n",
    "        return embed[:, -1]\n",
    "\n",
    "    # ====================================================\n",
    "    # Utilities\n",
    "    # ====================================================\n",
    "    def _prepare_obs(self, obs, is_first):\n",
    "        out = {}\n",
    "    \n",
    "        for k, v in obs.items():\n",
    "            t = torch.as_tensor(v, device=self.cfg.device)\n",
    "    \n",
    "            # Image: [H,W,C] → [1,H,W,C]\n",
    "            if k == \"image\" and t.ndim == 3:\n",
    "                t = t.unsqueeze(0)\n",
    "    \n",
    "            # Scalar → [1,1]\n",
    "            elif t.ndim == 0:\n",
    "                t = t.view(1, 1)\n",
    "    \n",
    "            # Vector → [1,D]\n",
    "            elif t.ndim == 1:\n",
    "                t = t.unsqueeze(0)\n",
    "    \n",
    "            out[k] = t\n",
    "    \n",
    "        # Ensure required Dreamer flags exist\n",
    "        if \"is_first\" not in out:\n",
    "            out[\"is_first\"] = torch.tensor(\n",
    "                [[float(is_first)]],\n",
    "                device=self.cfg.device,\n",
    "            )\n",
    "    \n",
    "        if \"is_terminal\" not in out:\n",
    "            out[\"is_terminal\"] = torch.zeros_like(out[\"is_first\"])\n",
    "    \n",
    "        if \"discount\" not in out:\n",
    "            out[\"discount\"] = torch.ones_like(out[\"is_first\"])\n",
    "    \n",
    "        return out\n",
    "\n",
    "    def _detach(self, latent):\n",
    "        return {k: v.detach() for k, v in latent.items()}\n",
    "\n",
    "    def _to_scalars(self, metrics):\n",
    "        out = {}\n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                out[k] = float(v.mean().detach().cpu())\n",
    "            elif isinstance(v, np.ndarray):\n",
    "                out[k] = float(v.mean())\n",
    "            else:\n",
    "                out[k] = float(v)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d53cb8b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.395446Z",
     "iopub.status.busy": "2026-01-02T05:23:45.394886Z",
     "iopub.status.idle": "2026-01-02T05:23:45.398886Z",
     "shell.execute_reply": "2026-01-02T05:23:45.398178Z"
    },
    "papermill": {
     "duration": 0.055599,
     "end_time": "2026-01-02T05:23:45.400443",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.344844",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def to_agent_obs(raw_obs):\n",
    "#     \"\"\"\n",
    "#     Convert env observation → agent-ready dict\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Case 1: tuple obs (Gym-style)\n",
    "#     if isinstance(raw_obs, tuple):\n",
    "#         raw_obs = raw_obs[0]\n",
    "\n",
    "#     # Case 2: dict obs\n",
    "#     if isinstance(raw_obs, dict):\n",
    "\n",
    "#         # 🔑 common patterns\n",
    "#         if \"image\" in raw_obs and not isinstance(raw_obs[\"image\"], dict):\n",
    "#             image = raw_obs[\"image\"]\n",
    "\n",
    "#         elif \"pixels\" in raw_obs:\n",
    "#             image = raw_obs[\"pixels\"]\n",
    "\n",
    "#         elif \"obs\" in raw_obs and isinstance(raw_obs[\"obs\"], dict):\n",
    "#             image = raw_obs[\"obs\"][\"image\"]\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 f\"Cannot find image in obs keys: {raw_obs.keys()}\"\n",
    "#             )\n",
    "\n",
    "#     else:\n",
    "#         # Case 3: raw image array\n",
    "#         image = raw_obs\n",
    "\n",
    "#     return {\n",
    "#         \"image\": image,   # MUST be H×W×C numpy array\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6f1bc",
   "metadata": {
    "papermill": {
     "duration": 0.04974,
     "end_time": "2026-01-02T05:23:45.499639",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.449899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f694a0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.599276Z",
     "iopub.status.busy": "2026-01-02T05:23:45.598910Z",
     "iopub.status.idle": "2026-01-02T05:23:45.603186Z",
     "shell.execute_reply": "2026-01-02T05:23:45.602468Z"
    },
    "papermill": {
     "duration": 0.056649,
     "end_time": "2026-01-02T05:23:45.604602",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.547953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_transition(replay, episode_id, transition, dataset_size):\n",
    "    \"\"\"\n",
    "    Append transition to replay.\n",
    "    Prune old episodes when dataset_size is exceeded.\n",
    "    \"\"\"\n",
    "    add_to_cache(replay, episode_id, transition)\n",
    "    erase_over_episodes(replay, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b3d5719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.702515Z",
     "iopub.status.busy": "2026-01-02T05:23:45.702215Z",
     "iopub.status.idle": "2026-01-02T05:23:45.706982Z",
     "shell.execute_reply": "2026-01-02T05:23:45.706307Z"
    },
    "papermill": {
     "duration": 0.054936,
     "end_time": "2026-01-02T05:23:45.708368",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.653432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_image(obs):\n",
    "    \"\"\"\n",
    "    Extract raw image as a numpy array (H,W,C).\n",
    "    Never uses boolean checks on arrays.\n",
    "    \"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        if \"image\" in obs:\n",
    "            img = obs[\"image\"]\n",
    "        elif \"pixel_values\" in obs:\n",
    "            img = obs[\"pixel_values\"]\n",
    "        else:\n",
    "            raise KeyError(\"obs dict has no 'image' or 'pixel_values' key\")\n",
    "    else:\n",
    "        img = obs\n",
    "\n",
    "    # Safety checks (recommended)\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        raise TypeError(f\"Expected image as np.ndarray, got {type(img)}\")\n",
    "    if img.dtype == object:\n",
    "        raise TypeError(\"Image has dtype=object, replay cannot store this\")\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17a7af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.807636Z",
     "iopub.status.busy": "2026-01-02T05:23:45.807028Z",
     "iopub.status.idle": "2026-01-02T05:23:45.812561Z",
     "shell.execute_reply": "2026-01-02T05:23:45.811924Z"
    },
    "papermill": {
     "duration": 0.056898,
     "end_time": "2026-01-02T05:23:45.813892",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.756994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_transition(\n",
    "    obs,\n",
    "    action,\n",
    "    reward,\n",
    "    discount,\n",
    "    is_first: bool,\n",
    "    is_terminal: bool,\n",
    "    is_last: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Transition for JEPA-1 + RSSM (Dreamer-style).\n",
    "\n",
    "    obs: dict-like (e.g. {\"image\": np.ndarray})\n",
    "    action: [A] or None\n",
    "    reward: scalar\n",
    "    discount: scalar (0.0 if terminal else 1.0)\n",
    "    is_first: True if episode reset\n",
    "    is_terminal: True if env terminated\n",
    "    is_last: True if this is final transition of episode\n",
    "    \"\"\"\n",
    "\n",
    "    out = dict(obs)\n",
    "\n",
    "    # --- action ---\n",
    "    if action is not None:\n",
    "        out[\"action\"] = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "    # --- scalars ---\n",
    "    out[\"reward\"] = np.asarray(reward, dtype=np.float32)\n",
    "    out[\"discount\"] = np.asarray(discount, dtype=np.float32)\n",
    "\n",
    "    # --- episode structure (CRITICAL) ---\n",
    "    out[\"is_first\"] = np.asarray(is_first, dtype=np.bool_)\n",
    "    out[\"is_terminal\"] = np.asarray(is_terminal, dtype=np.bool_)\n",
    "    out[\"is_last\"] = np.asarray(is_last, dtype=np.bool_)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "490645ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:45.911389Z",
     "iopub.status.busy": "2026-01-02T05:23:45.911092Z",
     "iopub.status.idle": "2026-01-02T05:23:45.915467Z",
     "shell.execute_reply": "2026-01-02T05:23:45.914755Z"
    },
    "papermill": {
     "duration": 0.054227,
     "end_time": "2026-01-02T05:23:45.916843",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.862616",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_available_sequences(replay, valid_eps, T):\n",
    "    \"\"\"\n",
    "    How many distinct length-T slices exist in replay across valid_eps.\n",
    "    If this >= batch_size, you can form a full batch without waiting.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for ep_id in list(valid_eps):\n",
    "        if ep_id not in replay:\n",
    "            continue\n",
    "        L = len(replay[ep_id].get(\"reward\", []))\n",
    "        total += max(0, L - T + 1)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4975c5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:46.015304Z",
     "iopub.status.busy": "2026-01-02T05:23:46.014687Z",
     "iopub.status.idle": "2026-01-02T05:23:46.021768Z",
     "shell.execute_reply": "2026-01-02T05:23:46.021096Z"
    },
    "papermill": {
     "duration": 0.058011,
     "end_time": "2026-01-02T05:23:46.023061",
     "exception": false,
     "start_time": "2026-01-02T05:23:45.965050",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def sample_fixed_length_from_replay(replay, valid_eps, T):\n",
    "    \"\"\"Return dict of arrays [T,...] or None if not ready.\"\"\"\n",
    "    if not valid_eps:\n",
    "        return None\n",
    "\n",
    "    ep_id = random.choice(tuple(valid_eps))\n",
    "    episode = replay.get(ep_id, None)\n",
    "    if episode is None:\n",
    "        return None\n",
    "\n",
    "    # IMPORTANT: replay stores lists per key, so np.asarray(list) is fine.\n",
    "    L = len(episode[\"reward\"])\n",
    "    if L < T:\n",
    "        return None\n",
    "\n",
    "    start = random.randint(0, L - T)\n",
    "\n",
    "    sample = {}\n",
    "    for k, v in episode.items():\n",
    "        arr = np.asarray(v)\n",
    "        sample[k] = arr[start:start + T]\n",
    "\n",
    "    # enforce invariants\n",
    "    sample[\"is_first\"] = np.zeros((T, 1), np.float32)\n",
    "    sample[\"is_first\"][0, 0] = 1.0\n",
    "\n",
    "    if \"is_terminal\" not in sample:\n",
    "        sample[\"is_terminal\"] = np.zeros((T, 1), np.float32)\n",
    "\n",
    "    if \"is_last\" not in sample:\n",
    "        sample[\"is_last\"] = np.zeros((T, 1), np.float32)\n",
    "        sample[\"is_last\"][-1, 0] = 1.0\n",
    "\n",
    "    if \"discount\" not in sample:\n",
    "        sample[\"discount\"] = np.ones((T, 1), np.float32)\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def fixed_length_generator(replay, valid_eps, T):\n",
    "    \"\"\"Never blocks: yields None until data is ready.\"\"\"\n",
    "    while True:\n",
    "        yield sample_fixed_length_from_replay(replay, valid_eps, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f9b864e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:46.122112Z",
     "iopub.status.busy": "2026-01-02T05:23:46.121527Z",
     "iopub.status.idle": "2026-01-02T05:23:46.130820Z",
     "shell.execute_reply": "2026-01-02T05:23:46.130213Z"
    },
    "papermill": {
     "duration": 0.059913,
     "end_time": "2026-01-02T05:23:46.132104",
     "exception": false,
     "start_time": "2026-01-02T05:23:46.072191",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def from_generator(\n",
    "    generator,\n",
    "    batch_size,\n",
    "    name=\"Collecting samples\",\n",
    "    max_tries=5000,\n",
    "    sleep_time=0.01,\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust online batcher.\n",
    "    Pulls fixed-length [T,...] samples into [T,B,...] Dreamer batches.\n",
    "    Never blocks forever; yields only when a full batch is ready.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        batch = []\n",
    "        tries = 0\n",
    "\n",
    "        p_collect = tqdm(\n",
    "            total=batch_size,\n",
    "            desc=f\"[GEN] {name}\",\n",
    "            leave=False,\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # Collect B samples safely\n",
    "        # -----------------------------\n",
    "        while len(batch) < batch_size and tries < max_tries:\n",
    "            sample = next(generator)\n",
    "            tries += 1\n",
    "\n",
    "            if sample is None:\n",
    "                time.sleep(sleep_time)\n",
    "                p_collect.set_postfix(waiting=\"replay not ready\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(sample, dict):\n",
    "                continue\n",
    "\n",
    "            batch.append(sample)\n",
    "            p_collect.update(1)\n",
    "            p_collect.set_postfix(collected=len(batch))\n",
    "\n",
    "        p_collect.close()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Not ready → wait and retry\n",
    "        # -----------------------------\n",
    "        if len(batch) < batch_size:\n",
    "            print(\n",
    "                f\"⚠️ [GEN] Only collected {len(batch)}/{batch_size} samples \"\n",
    "                f\"(replay not ready)\"\n",
    "            )\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Stack batch → [B,T,...]\n",
    "        # -----------------------------\n",
    "        first_val = batch[0][\"discount\"]   # stable Dreamer key\n",
    "        T = len(first_val)\n",
    "\n",
    "        all_keys = set().union(*(s.keys() for s in batch))\n",
    "        data = {}\n",
    "\n",
    "        for key in all_keys:\n",
    "            values = []\n",
    "            for i, s in enumerate(batch):\n",
    "                v = np.asarray(s[key])\n",
    "                if v.shape[0] != T:\n",
    "                    raise RuntimeError(\n",
    "                        f\"[GEN] time mismatch key '{key}' \"\n",
    "                        f\"sample {i}: expected {T}, got {v.shape[0]}\"\n",
    "                    )\n",
    "                values.append(v)\n",
    "\n",
    "            data[key] = np.stack(values, axis=0)  # [B,T,...]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Ensure Dreamer scalar shapes\n",
    "        # -----------------------------\n",
    "        for k in (\"reward\", \"discount\", \"is_first\", \"is_terminal\", \"is_last\"):\n",
    "            if k in data:\n",
    "                if data[k].ndim == 2:\n",
    "                    data[k] = data[k][..., None].astype(np.float32)\n",
    "                else:\n",
    "                    data[k] = data[k].astype(np.float32)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert to time-major [T,B,...]\n",
    "        # -----------------------------\n",
    "        for k, v in data.items():\n",
    "            if isinstance(v, np.ndarray) and v.ndim >= 2:\n",
    "                data[k] = np.swapaxes(v, 0, 1)\n",
    "\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "706479f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:46.230453Z",
     "iopub.status.busy": "2026-01-02T05:23:46.229597Z",
     "iopub.status.idle": "2026-01-02T05:23:46.234450Z",
     "shell.execute_reply": "2026-01-02T05:23:46.233754Z"
    },
    "papermill": {
     "duration": 0.055613,
     "end_time": "2026-01-02T05:23:46.235891",
     "exception": false,
     "start_time": "2026-01-02T05:23:46.180278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(batch, device):\n",
    "    # Move everything to torch\n",
    "    batch = {k: torch.as_tensor(v, device=device) for k, v in batch.items()}\n",
    "\n",
    "    # ---- is_first: MUST be float [B,T,1] ----\n",
    "    if \"is_first\" in batch:\n",
    "        batch[\"is_first\"] = batch[\"is_first\"].float()\n",
    "\n",
    "    # ---- is_terminal: keep semantic but convert ----\n",
    "    if \"is_terminal\" in batch:\n",
    "        batch[\"is_terminal\"] = batch[\"is_terminal\"].float()\n",
    "\n",
    "        # cont = 1 - terminal  (Dreamer convention)\n",
    "        batch[\"cont\"] = 1.0 - batch[\"is_terminal\"]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "018cb19e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:46.333896Z",
     "iopub.status.busy": "2026-01-02T05:23:46.333270Z",
     "iopub.status.idle": "2026-01-02T05:23:46.339882Z",
     "shell.execute_reply": "2026-01-02T05:23:46.339170Z"
    },
    "papermill": {
     "duration": 0.057026,
     "end_time": "2026-01-02T05:23:46.341581",
     "exception": false,
     "start_time": "2026-01-02T05:23:46.284555",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SequenceReplay:\n",
    "    def __init__(self, capacity, seq_len):\n",
    "        self.capacity = capacity\n",
    "        self.seq_len = seq_len\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, transition):\n",
    "        \"\"\"\n",
    "        transition: dict with keys\n",
    "        image, action, reward, discount, is_terminal\n",
    "        \"\"\"\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        return len(self.buffer) >= self.seq_len * batch_size\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns batch with shape [B, T, ...]\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            start = random.randint(\n",
    "                0, len(self.buffer) - self.seq_len\n",
    "            )\n",
    "            seq = list(self.buffer)[start : start + self.seq_len]\n",
    "            sequences.append(seq)\n",
    "\n",
    "        batch = {}\n",
    "        for key in sequences[0][0].keys():\n",
    "            batch[key] = np.stack(\n",
    "                [[step[key] for step in seq] for seq in sequences],\n",
    "                axis=0,  # [B,T,...]\n",
    "            )\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4165e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:46.439560Z",
     "iopub.status.busy": "2026-01-02T05:23:46.439201Z",
     "iopub.status.idle": "2026-01-02T05:23:58.217951Z",
     "shell.execute_reply": "2026-01-02T05:23:58.217093Z"
    },
    "papermill": {
     "duration": 11.829885,
     "end_time": "2026-01-02T05:23:58.219591",
     "exception": false,
     "start_time": "2026-01-02T05:23:46.389706",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b312270103a447d5bf4191d1129c6bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/785 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4b6c9fc26743368cfcbafbd8c43c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded JEPA-1 checkpoint\n"
     ]
    }
   ],
   "source": [
    "# highway\n",
    "# roundabout\n",
    "# merge\n",
    "replay = {}\n",
    "valid_eps = set()\n",
    "episode_len = defaultdict(int)\n",
    "\n",
    "world= HanoiWorldJEPA1(cfg)\n",
    "seq_gen = fixed_length_generator(\n",
    "    replay=replay,\n",
    "    valid_eps=valid_eps,\n",
    "    T=cfg.batch_length,\n",
    ")\n",
    "\n",
    "dataset = from_generator(\n",
    "    seq_gen,\n",
    "    cfg.batch_size,\n",
    ")\n",
    "\n",
    "logger = DummyLogger()\n",
    "froz_enc = FrozenJEPA1VisionEncoder(device=cfg.device,ckpt_root=CKPT_ROOT)\n",
    "agent= HanoiAgent(cfg, froz_enc, world)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4dbaab",
   "metadata": {
    "papermill": {
     "duration": 0.072464,
     "end_time": "2026-01-02T05:23:58.365205",
     "exception": false,
     "start_time": "2026-01-02T05:23:58.292741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e6cdc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:58.508440Z",
     "iopub.status.busy": "2026-01-02T05:23:58.507866Z",
     "iopub.status.idle": "2026-01-02T05:23:58.514807Z",
     "shell.execute_reply": "2026-01-02T05:23:58.513263Z"
    },
    "papermill": {
     "duration": 0.078479,
     "end_time": "2026-01-02T05:23:58.517156",
     "exception": false,
     "start_time": "2026-01-02T05:23:58.438677",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "def cfg_to_dict(cfg):\n",
    "    if hasattr(cfg, \"__dict__\"):\n",
    "        return vars(cfg)\n",
    "    if hasattr(cfg, \"_asdict\"):\n",
    "        return cfg._asdict()\n",
    "    return dict(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3cdc085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:58.661043Z",
     "iopub.status.busy": "2026-01-02T05:23:58.660004Z",
     "iopub.status.idle": "2026-01-02T05:23:58.671086Z",
     "shell.execute_reply": "2026-01-02T05:23:58.670323Z"
    },
    "papermill": {
     "duration": 0.085351,
     "end_time": "2026-01-02T05:23:58.673583",
     "exception": false,
     "start_time": "2026-01-02T05:23:58.588232",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_ckpt(step, agent, cfg, env_name):\n",
    "    os.makedirs(\"ckpts\", exist_ok=True)\n",
    "    path = f\"ckpts/ckpt_{step}.pt\"\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            # ---- metadata ----\n",
    "            \"step\": step,\n",
    "            \"env_name\": env_name,\n",
    "            \"cfg\": cfg_to_dict(cfg),\n",
    "\n",
    "            # ---- model weights ----\n",
    "            \"encoder\": agent.encoder.state_dict(),\n",
    "            \"world\": agent.world.state_dict(),\n",
    "\n",
    "            # ---- optimizer states ----\n",
    "            \"optimizers\": {\n",
    "                \"model\": agent.world.model_opt.state_dict(),\n",
    "                \"actor\": agent.world.actor_opt.state_dict(),\n",
    "                \"value\": agent.world.value_opt.state_dict(),\n",
    "            },\n",
    "        },\n",
    "        path,\n",
    "    )\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94488e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:58.830086Z",
     "iopub.status.busy": "2026-01-02T05:23:58.829688Z",
     "iopub.status.idle": "2026-01-02T05:23:58.834278Z",
     "shell.execute_reply": "2026-01-02T05:23:58.833461Z"
    },
    "papermill": {
     "duration": 0.082145,
     "end_time": "2026-01-02T05:23:58.836116",
     "exception": false,
     "start_time": "2026-01-02T05:23:58.753971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent.world.model_opt.load_state_dict(\n",
    "#     ckpt[\"optimizers\"][\"model\"]\n",
    "# )\n",
    "# agent.world.actor_opt.load_state_dict(\n",
    "#     ckpt[\"optimizers\"][\"actor\"]\n",
    "# )\n",
    "# agent.world.value_opt.load_state_dict(\n",
    "#     ckpt[\"optimizers\"][\"value\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f7d33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:58.992514Z",
     "iopub.status.busy": "2026-01-02T05:23:58.991863Z",
     "iopub.status.idle": "2026-01-02T05:23:58.997409Z",
     "shell.execute_reply": "2026-01-02T05:23:58.996504Z"
    },
    "papermill": {
     "duration": 0.087763,
     "end_time": "2026-01-02T05:23:58.999540",
     "exception": false,
     "start_time": "2026-01-02T05:23:58.911777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_scalar(x):\n",
    "    x = np.asarray(x)\n",
    "    return float(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03ddc381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T05:23:59.156666Z",
     "iopub.status.busy": "2026-01-02T05:23:59.155666Z",
     "iopub.status.idle": "2026-01-02T06:47:10.432028Z",
     "shell.execute_reply": "2026-01-02T06:47:10.431249Z"
    },
    "papermill": {
     "duration": 4991.356713,
     "end_time": "2026-01-02T06:47:10.433794",
     "exception": false,
     "start_time": "2026-01-02T05:23:59.077081",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorflow, tensorboard, torch, sklearn, keras.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/dtj-tran/hanoiworld/b9a848e37b504fa1b634e0375112c7ac\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bcca08821e40dd81f9148d2ae48444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5000 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : jepa_1_5000_roundabout\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/dtj-tran/hanoiworld/b9a848e37b504fa1b634e0375112c7ac\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     episode/start [98]       : (1, 98)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/avail_seqs [4824]  : (16, 730)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cont_loss [4824]   : (2.1007051600463456e-06, 0.5224051475524902)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dyn_loss [4824]    : (1.0, 7.078285217285156)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/kl [4824]          : (0.5657532215118408, 7.078285217285156)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/model_loss [4824]  : (1.9165866374969482, 10.310640335083008)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rep_loss [4824]    : (1.0, 7.078285217285156)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/reward_loss [4824] : (1.1830909252166748, 5.541262626647949)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/valid_eps [4824]   : (2, 53)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : jepa_1_5000_roundabout\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     act                                         : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     action_repeat                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|dist                                  : onehot\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|entropy                               : 0.0003\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|eps                                   : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|grad_clip                             : 100.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|layers                                : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|lr                                    : 3e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|max_std                               : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|min_std                               : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|outscale                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|std                                   : none\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|temp                                  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|unimix_ratio                          : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_length                                : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                                  : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     compile                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|layers                            : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|loss_scale                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|outscale                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|dist                                 : symlog_disc\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|eps                                  : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|grad_clip                            : 100.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|layers                               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|lr                                   : 3e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|outscale                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target_fraction                 : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target_update                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset_size                                : 20000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     debug                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|act                                 : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_depth                           : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_keys                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_sigmoid                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|image_dist                          : mse\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|kernel_size                         : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|minres                              : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_keys                            : $^\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_layers                          : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_units                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|norm                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|outscale                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|vector_dist                         : symlog_mse\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic_run                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device                                      : cuda\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_action_cond                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_layers                                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_log                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_models                                : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_offset                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_target                                : stoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_units                                 : 400\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     discount                                    : 0.997\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     discount_lambda                             : 0.95\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_deter                                   : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_discrete                                : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_hidden                                  : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_mean_act                                : none\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_min_std                                 : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_rec_depth                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_scale                                   : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_std_act                                 : sigmoid2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_stoch                                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed                                       : 128\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|act                                 : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|cnn_depth                           : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|cnn_keys                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|kernel_size                         : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|minres                              : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_keys                            : $^\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_layers                          : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_units                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|norm                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|symlog_inputs                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     envs                                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_episode_num                            : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_every                                  : 5000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_state_mean                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evaldir                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_behavior                               : greedy\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_extr_scale                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_intr_scale                             : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_until                                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_clip                                   : 1000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_heads                                  : ('decoder', 'reward', 'cont')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     graph_feat                                  : 13\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     graph_nodes                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grayscale                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_action_type                         : discrete\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_obs_type                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|collision_reward      : -1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|heading_reward        : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|high_speed_reward     : 0.25\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|lane_change_reward    : -0.03\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|min_safe_distance     : 8.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|on_road_reward        : 0.15\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|progress_reward_scale : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|reward_speed_range    : [8, 15]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|safe_distance_penalty : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|safe_distance_reward  : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|shaped_reward_weight  : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|success_reward        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|survival_reward       : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_shaping                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_success_mode                        : goal_flag\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_vehicles_count                      : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_visualize                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_gradient                               : reinforce\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_gradient_mix                           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_horizon                                : 15\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     initial                                     : learned\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kl_free                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_every                                   : 1000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logdir                                      : runs/rssm_jepa\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_lr                                    : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     norm                                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_actions                                 : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_evaldir                             : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_traindir                            : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opt                                         : adam\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opt_eps                                     : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     parallel                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     precision                                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     prefill                                     : 2500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrain                                    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rep_scale                                   : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reset_every                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_EMA                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|dist                            : symlog_disc\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|layers                          : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|loss_scale                      : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|outscale                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     size                                        : (64, 64)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                                       : 10000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task                                        : highway_roundabout\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time_limit                                  : 800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_ratio                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     traindir                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     traj_len                                    : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     unimix_ratio                                : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     units                                       : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     video_pred_log                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay                                : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                    : 4 (2.59 GB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (526 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorflow, tensorboard, torch, sklearn, keras.\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import traceback\n",
    "T = cfg.batch_length\n",
    "B = cfg.batch_size\n",
    "MAX_STEPS = 5000 # cfg.steps\n",
    "\n",
    "step = 0\n",
    "ep_id = 0\n",
    "done = True\n",
    "obs = None\n",
    "agent_state = None\n",
    "\n",
    "comet_exp = Experiment(\n",
    "        api_key=os.getenv(\"API_KEY\"),\n",
    "        project_name=os.getenv(\"PROJECT_NAME\", \"hanoiworld\"),\n",
    "        workspace=os.getenv(\"WORK_SPACE\"),\n",
    "        auto_output_logging=\"simple\",\n",
    "        parse_args=False,\n",
    "    )\n",
    "\n",
    "comet_exp.set_name(f\"jepa_1_{MAX_STEPS}_{env_name}\")\n",
    "comet_exp.log_parameters({\n",
    "    \"batch_length\": T,\n",
    "    \"batch_size\": B,\n",
    "})\n",
    "comet_exp.log_parameters(cfg_to_dict(cfg))\n",
    "CKPT_INTERVAL = 1000  # or 1000\n",
    "try:\n",
    "    with tqdm(total=MAX_STEPS, desc=\"Train\", unit=\"step\") as pbar:\n",
    "\n",
    "        while step < MAX_STEPS:\n",
    "\n",
    "            # =====================================================\n",
    "            # (1) Episode reset\n",
    "            # =====================================================\n",
    "            if done:\n",
    "                ep_id += 1\n",
    "                obs, _ = env.reset()\n",
    "                agent_state = None\n",
    "                episode_len[ep_id] = 0\n",
    "\n",
    "                add_transition(\n",
    "                    replay,\n",
    "                    ep_id,\n",
    "                    build_transition(\n",
    "                        obs,\n",
    "                        action=np.zeros(cfg.num_actions, np.float32),\n",
    "                        reward=0.0,\n",
    "                        discount=1.0,\n",
    "                        is_first=True,\n",
    "                        is_terminal=False,\n",
    "                        is_last=False,\n",
    "                    ),\n",
    "                    dataset_size=None,\n",
    "                )\n",
    "\n",
    "                done = False\n",
    "                comet_exp.log_metric(\"episode/start\", ep_id, step=step)\n",
    "\n",
    "            # =====================================================\n",
    "            # (2) Policy step (NO training yet)\n",
    "            # =====================================================\n",
    "            image = extract_image(obs)\n",
    "\n",
    "            policy_out, agent_state = agent.act(\n",
    "                obs,\n",
    "                agent_state,\n",
    "                training=True,\n",
    "            )\n",
    "\n",
    "            action = policy_out[\"action\"].cpu().numpy()[0]\n",
    "\n",
    "            # =====================================================\n",
    "            # (3) Environment step\n",
    "            # =====================================================\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            is_terminal = bool(terminated)\n",
    "            is_last = bool(terminated or truncated)\n",
    "            discount = 0.0 if is_terminal else 1.0\n",
    "            done = is_last\n",
    "\n",
    "            is_first = (episode_len[ep_id] == 0)\n",
    "\n",
    "            add_transition(\n",
    "                replay,\n",
    "                ep_id,\n",
    "                build_transition(\n",
    "                    next_obs,\n",
    "                    action=action,\n",
    "                    reward=reward,\n",
    "                    discount=discount,\n",
    "                    is_first=is_first,\n",
    "                    is_terminal=is_terminal,\n",
    "                    is_last=is_last,\n",
    "                ),\n",
    "                dataset_size=None,\n",
    "            )\n",
    "\n",
    "            episode_len[ep_id] += 1\n",
    "            obs = next_obs\n",
    "\n",
    "            # mark episode valid once it can produce a sequence\n",
    "            if episode_len[ep_id] >= T:\n",
    "                valid_eps.add(ep_id)\n",
    "\n",
    "            # =====================================================\n",
    "            # (4) TRAINING STEP (offline)\n",
    "            # =====================================================\n",
    "            avail_seqs = count_available_sequences(replay, valid_eps, T)\n",
    "\n",
    "            if avail_seqs >= B:\n",
    "\n",
    "                # ---- sample B episodes ----\n",
    "                eps = random.choices(list(valid_eps), k=B)\n",
    "                batch = defaultdict(list)\n",
    "\n",
    "                for ep in eps:\n",
    "                    L = len(replay[ep][\"reward\"])\n",
    "                    start = random.randint(0, L - T)\n",
    "\n",
    "                    for k, v in replay[ep].items():\n",
    "                        batch[k].append(v[start:start+T])\n",
    "\n",
    "                # ---- stack to [B, T, ...] ----\n",
    "                batch = {k: np.stack(v, axis=0) for k, v in batch.items()}\n",
    "                batch = {k: torch.as_tensor(v, device=cfg.device) for k, v in batch.items()}\n",
    "\n",
    "                # ---- encode observations ----\n",
    "                batch[\"embed\"] = agent.encode_sequence(batch)   # [B,T,D]\n",
    "\n",
    "                # ---- preprocess ----\n",
    "                batch = preprocess(batch, cfg.device)\n",
    "\n",
    "                # ---- world model update ----\n",
    "                post, _, metrics = agent.world.train_model(batch)\n",
    "\n",
    "                # ---- logging ----\n",
    "                comet_exp.log_metrics({\n",
    "                    \"train/model_loss\": to_scalar(metrics[\"model_loss\"]),\n",
    "                    \"train/kl\": to_scalar(metrics[\"kl\"]),\n",
    "                    \"train/reward_loss\": to_scalar(metrics[\"reward_loss\"]),\n",
    "                    \"train/cont_loss\": to_scalar(metrics[\"cont_loss\"]),\n",
    "                    \"train/dyn_loss\": to_scalar(metrics[\"dyn_loss\"]),\n",
    "                    \"train/rep_loss\": to_scalar(metrics[\"rep_loss\"]),\n",
    "                    \"train/valid_eps\": len(valid_eps),\n",
    "                    \"train/avail_seqs\": avail_seqs,\n",
    "                }, step=step)\n",
    "\n",
    "            # =====================================================\n",
    "            # (5) Progress\n",
    "            # =====================================================\n",
    "            if step % CKPT_INTERVAL == 0 and step > 0:\n",
    "                ckpt_path = save_ckpt(\n",
    "                    step=step,\n",
    "                    agent=agent,\n",
    "                    cfg=cfg,\n",
    "                    env_name=env_name,\n",
    "                )\n",
    "                \n",
    "                comet_exp.log_asset(\n",
    "                    ckpt_path,\n",
    "                    step=step,\n",
    "                )\n",
    "            step += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\n",
    "                \"ep\": ep_id,\n",
    "                \"valid_eps\": len(valid_eps),\n",
    "                \"avail_seqs\": avail_seqs,\n",
    "                \"reward\": f\"{reward:.2f}\",\n",
    "            })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL-SAFE] Training crashed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    comet_exp.log_other(\"crash\", str(e))\n",
    "\n",
    "finally:\n",
    "    comet_exp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1ffa02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T06:47:10.547645Z",
     "iopub.status.busy": "2026-01-02T06:47:10.547053Z",
     "iopub.status.idle": "2026-01-02T06:47:10.550557Z",
     "shell.execute_reply": "2026-01-02T06:47:10.549977Z"
    },
    "papermill": {
     "duration": 0.06137,
     "end_time": "2026-01-02T06:47:10.551879",
     "exception": false,
     "start_time": "2026-01-02T06:47:10.490509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent.world.model_opt\n",
    "# agent.world.actor_opt\n",
    "# agent.world.value_opt\n",
    "#  # self.model_opt, self.actor_opt, self.value_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00cf94",
   "metadata": {
    "papermill": {
     "duration": 0.057397,
     "end_time": "2026-01-02T06:47:10.668380",
     "exception": false,
     "start_time": "2026-01-02T06:47:10.610983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13fb04d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T06:47:10.783627Z",
     "iopub.status.busy": "2026-01-02T06:47:10.783310Z",
     "iopub.status.idle": "2026-01-02T06:47:10.789026Z",
     "shell.execute_reply": "2026-01-02T06:47:10.788397Z"
    },
    "papermill": {
     "duration": 0.065066,
     "end_time": "2026-01-02T06:47:10.790395",
     "exception": false,
     "start_time": "2026-01-02T06:47:10.725329",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Evaluation Procedure for Autonomous Driving Policy\n",
    "# ============================================================\n",
    "#\n",
    "# Inputs:\n",
    "#   - env: evaluation environment\n",
    "#   - agent: trained policy\n",
    "#   - episodes: number of evaluation episodes\n",
    "#   - w_drive = (w1, w2, w3): weights for driving score\n",
    "#   - config: evaluation configuration (success definition)\n",
    "#\n",
    "# Outputs:\n",
    "#   - results: per-episode metrics\n",
    "#   - summary: aggregated mean ± std statistics\n",
    "#   - minADE_available_episodes: count of episodes with valid minADE\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# Initialize containers\n",
    "# ------------------------------------------------------------\n",
    "# results = {\n",
    "#   \"collision_rate\": [],\n",
    "#   \"offroad_rate\": [],\n",
    "#   \"success\": [],\n",
    "#   \"lateral_deviation\": [],\n",
    "#   \"avg_reward\": [],\n",
    "#   \"minADE\": [],\n",
    "#   \"driving_score\": [],\n",
    "# }\n",
    "# minADE_available = []\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# For each evaluation episode\n",
    "# ------------------------------------------------------------\n",
    "# for episode in range(episodes):\n",
    "#\n",
    "#   # Reset environment and agent\n",
    "#   obs, info = env.reset()\n",
    "#   agent.reset()\n",
    "#\n",
    "#   done = False\n",
    "#   total_reward = 0\n",
    "#   steps = 0\n",
    "#\n",
    "#   # Step-level accumulators\n",
    "#   collision_frames = 0\n",
    "#   offroad_steps = 0\n",
    "#   lateral_deviations = []\n",
    "#   route_progress = 0\n",
    "#\n",
    "#   route_total_length = info.get(\"route_length\", 1.0)\n",
    "#\n",
    "#   predicted_positions = []\n",
    "#   true_positions = []\n",
    "#\n",
    "#   # --------------------------------------------------------\n",
    "#   # Rollout episode\n",
    "#   # --------------------------------------------------------\n",
    "#   while not done:\n",
    "#\n",
    "#       # Query policy\n",
    "#       action = agent(obs)\n",
    "#\n",
    "#       # Environment transition\n",
    "#       obs, reward, terminated, truncated, info = env.step(action)\n",
    "#       done = terminated or truncated\n",
    "#\n",
    "#       total_reward += reward\n",
    "#       steps += 1\n",
    "#\n",
    "#       # ----------------------------------------------------\n",
    "#       # Step-level metrics\n",
    "#       # ----------------------------------------------------\n",
    "#       collision_frames += int(info.get(\"crashed\", False))\n",
    "#       offroad_steps += info.get(\"off_road\", 0)\n",
    "#       route_progress += info.get(\"route_progress\", 0)\n",
    "#\n",
    "#       # Lateral deviation (preferred order)\n",
    "#       if \"lateral_offset_signed\" in info:\n",
    "#           lateral_deviations.append(abs(float(info[\"lateral_offset_signed\"])))\n",
    "#       elif \"lateral_offset_abs\" in info:\n",
    "#           lateral_deviations.append(float(info[\"lateral_offset_abs\"]))\n",
    "#       elif \"ego_position\" in info and \"lane_center\" in info:\n",
    "#           lateral_deviations.append(\n",
    "#               || ego_position - lane_center ||\n",
    "#           )\n",
    "#\n",
    "#       # Trajectory prediction logging (for minADE)\n",
    "#       if \"predicted_position\" in info and \"true_future_position\" in info:\n",
    "#           predicted_positions.append(info[\"predicted_position\"])\n",
    "#           true_positions.append(info[\"true_future_position\"])\n",
    "#\n",
    "#   # --------------------------------------------------------\n",
    "#   # Episode-level metrics\n",
    "#   # --------------------------------------------------------\n",
    "#   collision_rate = 1.0 if collision_frames > 0 else 0.0\n",
    "#   offroad_rate = offroad_steps / max(steps, 1)\n",
    "#\n",
    "#   if config.highway_success_mode == \"no_collision_episode\":\n",
    "#       success = int(collision_frames == 0 and offroad_steps == 0)\n",
    "#   else:\n",
    "#       success = int(collision_frames == 0 and info.get(\"goal_reached\", False))\n",
    "#\n",
    "#   lateral_deviation = mean(lateral_deviations) if lateral_deviations else 0.0\n",
    "#   avg_reward = total_reward\n",
    "#\n",
    "#   # --------------------------------------------------------\n",
    "#   # Trajectory prediction metric (minADE)\n",
    "#   # --------------------------------------------------------\n",
    "#   if predicted_positions:\n",
    "#       minADE = mean(L2(predicted_positions - true_positions))\n",
    "#       minADE_available.append(True)\n",
    "#   else:\n",
    "#       minADE = NaN\n",
    "#       minADE_available.append(False)\n",
    "#\n",
    "#   # --------------------------------------------------------\n",
    "#   # Driving score (safety + rule adherence + comfort)\n",
    "#   # --------------------------------------------------------\n",
    "#   comfort_index = info.get(\"comfort_index\", 0.0)\n",
    "#   discomfort = -log(max(comfort_index, epsilon))\n",
    "#   comfort_term = 1 / (1 + discomfort)\n",
    "#\n",
    "#   driving_score = (\n",
    "#       w1 * (1 - collision_rate) +\n",
    "#       w2 * (1 - offroad_rate) +\n",
    "#       w3 * comfort_term\n",
    "#   )\n",
    "#\n",
    "#   # --------------------------------------------------------\n",
    "#   # Store results\n",
    "#   # --------------------------------------------------------\n",
    "#   results[\"collision_rate\"].append(collision_rate)\n",
    "#   results[\"offroad_rate\"].append(offroad_rate)\n",
    "#   results[\"success\"].append(success)\n",
    "#   results[\"lateral_deviation\"].append(lateral_deviation)\n",
    "#   results[\"avg_reward\"].append(avg_reward)\n",
    "#   results[\"minADE\"].append(minADE)\n",
    "#   results[\"driving_score\"].append(driving_score)\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# Aggregate statistics (mean ± std, ignoring NaN)\n",
    "# ------------------------------------------------------------\n",
    "# summary = {}\n",
    "# for metric, values in results.items():\n",
    "#     summary[metric] = (nanmean(values), nanstd(values))\n",
    "#\n",
    "# summary[\"minADE_available_episodes\"] = (\n",
    "#     sum(minADE_available),\n",
    "#     len(minADE_available)\n",
    "# )\n",
    "#\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a6d2c",
   "metadata": {
    "papermill": {
     "duration": 0.055513,
     "end_time": "2026-01-02T06:47:10.905674",
     "exception": false,
     "start_time": "2026-01-02T06:47:10.850161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "328cdb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T06:47:11.017830Z",
     "iopub.status.busy": "2026-01-02T06:47:11.017539Z",
     "iopub.status.idle": "2026-01-02T06:54:47.003337Z",
     "shell.execute_reply": "2026-01-02T06:54:47.002749Z"
    },
    "papermill": {
     "duration": 456.043841,
     "end_time": "2026-01-02T06:54:47.005065",
     "exception": false,
     "start_time": "2026-01-02T06:47:10.961224",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorflow, tensorboard, torch, sklearn, keras.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/dtj-tran/hanoiworld/f8aba4f98f604e848abdeb3826199a4a\n",
      "\n",
      "Evaluate: 100%|██████████| 100/100 [07:32<00:00,  4.53s/episode, reward=3.28, success=0, collision=1]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : jepa_1_5000_100_roundabout_eval\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/dtj-tran/hanoiworld/f8aba4f98f604e848abdeb3826199a4a\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/collision_rate [100]         : (0.0, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/driving_score [100]          : (0.4285714285714286, 1.5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/lateral_deviation [100]      : (0.04970532143702955, 0.5119416518323339)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/minADE [100]                 : (1.0564974546432495, 1.3260407447814941)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/offroad_rate [100]           : (0.0, 0.14285714285714285)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/reward [100]                 : (1.178932088707755, 19.803227548802507)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/success                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/collision_rate_mean       : 0.3400000035762787\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/collision_rate_std        : 0.4737088084220886\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/driving_score_mean        : 1.146562933921814\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/driving_score_std         : 0.48348018527030945\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/lateral_deviation_mean    : 0.22121989727020264\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/lateral_deviation_std     : 0.1089329868555069\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/minADE_available_episodes : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/minADE_mean               : 1.2676583528518677\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/minADE_std                : 0.08065847307443619\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/offroad_rate_mean         : 0.026874391362071037\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/offroad_rate_std          : 0.03465166315436363\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/reward_mean               : 9.818094253540039\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/reward_std                : 6.252089023590088\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/success_mean              : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     summary/success_std               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : jepa_1_5000_100_roundabout_eval\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : evaluation\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     act                                         : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     action_repeat                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|dist                                  : onehot\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|entropy                               : 0.0003\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|eps                                   : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|grad_clip                             : 100.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|layers                                : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|lr                                    : 3e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|max_std                               : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|min_std                               : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|outscale                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|std                                   : none\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|temp                                  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     actor|unimix_ratio                          : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_length                                : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                                  : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     compile                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|layers                            : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|loss_scale                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cont_head|outscale                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|dist                                 : symlog_disc\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|eps                                  : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|grad_clip                            : 100.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|layers                               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|lr                                   : 3e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|outscale                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target_fraction                 : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     critic|slow_target_update                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataset_size                                : 20000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     debug                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|act                                 : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_depth                           : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_keys                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|cnn_sigmoid                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|image_dist                          : mse\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|kernel_size                         : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|minres                              : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_keys                            : $^\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_layers                          : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|mlp_units                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|norm                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|outscale                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder|vector_dist                         : symlog_mse\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic_run                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device                                      : cuda\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_action_cond                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_layers                                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_log                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_models                                : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_offset                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_target                                : stoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disag_units                                 : 400\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     discount                                    : 0.997\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     discount_lambda                             : 0.95\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_deter                                   : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_discrete                                : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_hidden                                  : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_mean_act                                : none\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_min_std                                 : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_rec_depth                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_scale                                   : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_std_act                                 : sigmoid2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dyn_stoch                                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed                                       : 128\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|act                                 : SiLU\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|cnn_depth                           : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|cnn_keys                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|kernel_size                         : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|minres                              : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_keys                            : $^\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_layers                          : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|mlp_units                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|norm                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder|symlog_inputs                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     envs                                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_episode_num                            : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_every                                  : 5000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_state_mean                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evaldir                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_behavior                               : greedy\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_extr_scale                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_intr_scale                             : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     expl_until                                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_clip                                   : 1000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_heads                                  : ('decoder', 'reward', 'cont')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     graph_feat                                  : 13\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     graph_nodes                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grayscale                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_action_type                         : discrete\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_obs_type                            : image\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|collision_reward      : -1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|heading_reward        : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|high_speed_reward     : 0.25\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|lane_change_reward    : -0.03\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|min_safe_distance     : 8.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|on_road_reward        : 0.15\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|progress_reward_scale : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|reward_speed_range    : [8, 15]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|safe_distance_penalty : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|safe_distance_reward  : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|shaped_reward_weight  : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|success_reward        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_config|survival_reward       : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_reward_shaping                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_success_mode                        : goal_flag\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_vehicles_count                      : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     highway_visualize                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_gradient                               : reinforce\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_gradient_mix                           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imag_horizon                                : 15\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     initial                                     : learned\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kl_free                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_every                                   : 1000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logdir                                      : runs/rssm_jepa\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_lr                                    : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     norm                                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_actions                                 : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_evaldir                             : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_traindir                            : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opt                                         : adam\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opt_eps                                     : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     parallel                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     precision                                   : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     prefill                                     : 2500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrain                                    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rep_scale                                   : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reset_every                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_EMA                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|dist                            : symlog_disc\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|layers                          : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|loss_scale                      : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     reward_head|outscale                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     size                                        : (64, 64)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                                       : 10000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task                                        : highway_roundabout\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time_limit                                  : 800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_ratio                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     traindir                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     traj_len                                    : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     unimix_ratio                                : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     units                                       : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     video_pred_log                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay                                : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (526 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary/reward_mean: 9.818094253540039\n",
      "summary/reward_std: 6.252089023590088\n",
      "summary/collision_rate_mean: 0.3400000035762787\n",
      "summary/collision_rate_std: 0.4737088084220886\n",
      "summary/offroad_rate_mean: 0.026874391362071037\n",
      "summary/offroad_rate_std: 0.03465166315436363\n",
      "summary/success_mean: 0.0\n",
      "summary/success_std: 0.0\n",
      "summary/lateral_deviation_mean: 0.22121989727020264\n",
      "summary/lateral_deviation_std: 0.1089329868555069\n",
      "summary/minADE_mean: 1.2676583528518677\n",
      "summary/minADE_std: 0.08065847307443619\n",
      "summary/driving_score_mean: 1.146562933921814\n",
      "summary/driving_score_std: 0.48348018527030945\n",
      "summary/minADE_available_episodes: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorflow, tensorboard, torch, sklearn, keras.\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# =====================================================\n",
    "# Evaluation configuration\n",
    "# =====================================================\n",
    "EPISODES = 100 #cfg.eval_episodes\n",
    "w_drive = (1.0, 0.5, 0.0)#cfg.w_drive  # (collision, offroad, comfort)\n",
    "\n",
    "# =====================================================\n",
    "# Comet experiment\n",
    "# =====================================================\n",
    "comet_exp = Experiment(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    project_name=os.getenv(\"PROJECT_NAME\", \"hanoiworld\"),\n",
    "    workspace=os.getenv(\"WORK_SPACE\"),\n",
    "    auto_output_logging=\"simple\",\n",
    "    parse_args=False,\n",
    ")\n",
    "comet_exp.set_name(f\"jepa_1_{MAX_STEPS}_{EPISODES}_{env_name}_eval\")\n",
    "comet_exp.log_parameters(cfg_to_dict(cfg))\n",
    "comet_exp.log_other(\"mode\", \"evaluation\")\n",
    "\n",
    "# =====================================================\n",
    "# Result containers\n",
    "# =====================================================\n",
    "results = defaultdict(list)\n",
    "minADE_available = []\n",
    "\n",
    "try:\n",
    "    with tqdm(total=EPISODES, desc=\"Evaluate\", unit=\"episode\") as pbar:\n",
    "\n",
    "        for ep in range(EPISODES):\n",
    "\n",
    "            # =====================================================\n",
    "            # (1) Episode reset\n",
    "            # =====================================================\n",
    "            obs, info = env.reset()\n",
    "            # agent.reset()\n",
    "            agent_state = None\n",
    "            done = False\n",
    "\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            collision_frames = 0\n",
    "            offroad_steps = 0\n",
    "            lateral_devs = []\n",
    "\n",
    "            predicted_positions = []\n",
    "            true_positions = []\n",
    "\n",
    "            # =====================================================\n",
    "            # (2) Rollout\n",
    "            # =====================================================\n",
    "            while not done:\n",
    "\n",
    "                policy_out, agent_state = agent.act(\n",
    "                    obs,\n",
    "                    agent_state,\n",
    "                    training=False,   # 🔴 IMPORTANT\n",
    "                )\n",
    "\n",
    "                action = policy_out[\"action\"].cpu().numpy()[0]\n",
    "\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "                done = terminated or truncated\n",
    "\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "\n",
    "                # -------------------------------------------------\n",
    "                # Step-level metrics\n",
    "                # -------------------------------------------------\n",
    "                collision_frames += int(info.get(\"crashed\", False))\n",
    "                offroad_steps += int(info.get(\"off_road\", 0))\n",
    "\n",
    "                if \"lateral_offset_signed\" in info:\n",
    "                    lateral_devs.append(abs(float(info[\"lateral_offset_signed\"])))\n",
    "                elif \"lateral_offset_abs\" in info:\n",
    "                    lateral_devs.append(float(info[\"lateral_offset_abs\"]))\n",
    "                elif \"ego_position\" in info and \"lane_center\" in info:\n",
    "                    lateral_devs.append(\n",
    "                        np.linalg.norm(\n",
    "                            np.array(info[\"ego_position\"]) -\n",
    "                            np.array(info[\"lane_center\"])\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if \"predicted_position\" in info and \"true_future_position\" in info:\n",
    "                    predicted_positions.append(np.array(info[\"predicted_position\"]))\n",
    "                    true_positions.append(np.array(info[\"true_future_position\"]))\n",
    "\n",
    "            # =====================================================\n",
    "            # (3) Episode-level metrics\n",
    "            # =====================================================\n",
    "            collision_rate = 1.0 if collision_frames > 0 else 0.0\n",
    "            offroad_rate = offroad_steps / max(steps, 1)\n",
    "\n",
    "            success_mode = getattr(cfg, \"highway_success_mode\", \"goal_flag\")\n",
    "            if success_mode == \"no_collision_episode\":\n",
    "                success = int(collision_frames == 0 and offroad_steps == 0)\n",
    "            else:\n",
    "                success = int(\n",
    "                    collision_frames == 0 and info.get(\"goal_reached\", False)\n",
    "                )\n",
    "\n",
    "            lateral_deviation = np.mean(lateral_devs) if lateral_devs else 0.0\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # minADE\n",
    "            # -------------------------------------------------\n",
    "            if predicted_positions:\n",
    "                pred = np.stack(predicted_positions)\n",
    "                true = np.stack(true_positions)\n",
    "                minADE = np.mean(np.linalg.norm(pred - true, axis=1))\n",
    "                minADE_available.append(True)\n",
    "            else:\n",
    "                minADE = np.nan\n",
    "                minADE_available.append(False)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # Driving score\n",
    "            # -------------------------------------------------\n",
    "            comfort_index = float(info.get(\"comfort_index\", 0.0) or 0.0)\n",
    "            discomfort = -np.log(max(comfort_index, 1e-6))\n",
    "            comfort_term = 1.0 / (1.0 + discomfort)\n",
    "\n",
    "            driving_score = (\n",
    "                w_drive[0] * (1 - collision_rate) +\n",
    "                w_drive[1] * (1 - offroad_rate) +\n",
    "                w_drive[2] * comfort_term\n",
    "            )\n",
    "\n",
    "            # =====================================================\n",
    "            # (4) Logging\n",
    "            # =====================================================\n",
    "            comet_exp.log_metrics({\n",
    "                \"eval/reward\": total_reward,\n",
    "                \"eval/collision_rate\": collision_rate,\n",
    "                \"eval/offroad_rate\": offroad_rate,\n",
    "                \"eval/success\": success,\n",
    "                \"eval/lateral_deviation\": lateral_deviation,\n",
    "                \"eval/minADE\": minADE,\n",
    "                \"eval/driving_score\": driving_score,\n",
    "            }, step=ep)\n",
    "\n",
    "            # Store for aggregation\n",
    "            results[\"reward\"].append(total_reward)\n",
    "            results[\"collision_rate\"].append(collision_rate)\n",
    "            results[\"offroad_rate\"].append(offroad_rate)\n",
    "            results[\"success\"].append(success)\n",
    "            results[\"lateral_deviation\"].append(lateral_deviation)\n",
    "            results[\"minADE\"].append(minADE)\n",
    "            results[\"driving_score\"].append(driving_score)\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\n",
    "                \"reward\": f\"{total_reward:.2f}\",\n",
    "                \"success\": success,\n",
    "                \"collision\": collision_rate,\n",
    "            })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL-SAFE] Evaluation crashed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    comet_exp.log_other(\"crash\", str(e))\n",
    "\n",
    "finally:\n",
    "    # =====================================================\n",
    "    # (5) Aggregate statistics\n",
    "    # =====================================================\n",
    "    summary = {}\n",
    "    for k, v in results.items():\n",
    "        arr = np.asarray(v, dtype=np.float32)\n",
    "        summary[k + \"_mean\"] = np.nanmean(arr)\n",
    "        summary[k + \"_std\"] = np.nanstd(arr)\n",
    "\n",
    "    summary[\"minADE_available_episodes\"] = sum(minADE_available)\n",
    "\n",
    "    for k, v in summary.items():\n",
    "        print(f\"summary/{k}: {v}\")\n",
    "    comet_exp.log_metrics({f\"summary/{k}\": v for k, v in summary.items()})\n",
    "    comet_exp.end()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelId": 546690,
     "modelInstanceId": 532954,
     "sourceId": 702322,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5611.521777,
   "end_time": "2026-01-02T06:54:50.312802",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T05:21:18.791025",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "002e3e03e8a4471a95f44a3a4b899bdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2006b2c7bd11498aa85cdb1a7688f146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dcd731e38cd54336a68eecc6634eeda8",
       "placeholder": "​",
       "style": "IPY_MODEL_d319a0727739433c895d85938e72ac06",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "31c4ef0a0cc140ebad12e96df2ac67cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37c61e7a191f4e71a7d89cac93575756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_31c4ef0a0cc140ebad12e96df2ac67cd",
       "max": 785.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45e74dbe83954ebb85665c0bb0eb6e69",
       "tabbable": null,
       "tooltip": null,
       "value": 785.0
      }
     },
     "3a183a93cd4b46c6af71aaec4cc4beaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59880e0fe40b4f4dbbd14250f8b2f317",
       "placeholder": "​",
       "style": "IPY_MODEL_ed47dedde4234175893df210f44208de",
       "tabbable": null,
       "tooltip": null,
       "value": " 785/785 [00:00&lt;00:00, 92.9kB/s]"
      }
     },
     "3f8572b7580645db89f24790f429afb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7fce56896286470787d60e3397d433fc",
       "max": 1303947864.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db7424d1e44548dfb641606a5a9b1c3d",
       "tabbable": null,
       "tooltip": null,
       "value": 1303947864.0
      }
     },
     "42bcca08821e40dd81f9148d2ae48444": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b9178f05cab64188bfb5f30482a9dc34",
        "IPY_MODEL_d9a9db0436be4d53be725c74c3e7cc66",
        "IPY_MODEL_a1801439488947aab865a140c7bfc2bd"
       ],
       "layout": "IPY_MODEL_e39c34e0d09b428db95c5d00f84bec8f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "45e74dbe83954ebb85665c0bb0eb6e69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4767c40ccb08492aac066f7f0d438a8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5f6acc9b4b8d413c87f564bf15fcf3d6",
       "placeholder": "​",
       "style": "IPY_MODEL_002e3e03e8a4471a95f44a3a4b899bdd",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.30G/1.30G [00:03&lt;00:00, 897MB/s]"
      }
     },
     "544e11be8e6641388c54c11a20051821": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59880e0fe40b4f4dbbd14250f8b2f317": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c14319ccbd34f868d000704c069ff64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f6acc9b4b8d413c87f564bf15fcf3d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6172c7efddca44e19859a7aa9a6c0109": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "694bba65c30944fe86685f4b0d7436c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75af5bfb45704419a5fba05a7d1f78ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cf394998e1448e29055ab6aeed9ba07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7fce56896286470787d60e3397d433fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b3c85ff8ea041ce9593005e129e254e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1801439488947aab865a140c7bfc2bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b3c85ff8ea041ce9593005e129e254e",
       "placeholder": "​",
       "style": "IPY_MODEL_b53640316b064650a1bdeedb8919b17a",
       "tabbable": null,
       "tooltip": null,
       "value": " 5000/5000 [1:22:56&lt;00:00,  1.02s/step, ep=98, valid_eps=53, avail_seqs=730, reward=0.39]"
      }
     },
     "b312270103a447d5bf4191d1129c6bdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2006b2c7bd11498aa85cdb1a7688f146",
        "IPY_MODEL_37c61e7a191f4e71a7d89cac93575756",
        "IPY_MODEL_3a183a93cd4b46c6af71aaec4cc4beaa"
       ],
       "layout": "IPY_MODEL_7cf394998e1448e29055ab6aeed9ba07",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b53640316b064650a1bdeedb8919b17a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b9178f05cab64188bfb5f30482a9dc34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_544e11be8e6641388c54c11a20051821",
       "placeholder": "​",
       "style": "IPY_MODEL_694bba65c30944fe86685f4b0d7436c6",
       "tabbable": null,
       "tooltip": null,
       "value": "Train: 100%"
      }
     },
     "d319a0727739433c895d85938e72ac06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d9a9db0436be4d53be725c74c3e7cc66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e88f4f311b64451ead7815684afdc790",
       "max": 5000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5c14319ccbd34f868d000704c069ff64",
       "tabbable": null,
       "tooltip": null,
       "value": 5000.0
      }
     },
     "db7424d1e44548dfb641606a5a9b1c3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dcd731e38cd54336a68eecc6634eeda8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e39c34e0d09b428db95c5d00f84bec8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e88f4f311b64451ead7815684afdc790": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed47dedde4234175893df210f44208de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ee62a0f669e44cd0b3fe25512a558394": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75af5bfb45704419a5fba05a7d1f78ff",
       "placeholder": "​",
       "style": "IPY_MODEL_f506067aa7b14f448f14099cc869c260",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "f506067aa7b14f448f14099cc869c260": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fc4b6c9fc26743368cfcbafbd8c43c5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ee62a0f669e44cd0b3fe25512a558394",
        "IPY_MODEL_3f8572b7580645db89f24790f429afb3",
        "IPY_MODEL_4767c40ccb08492aac066f7f0d438a8a"
       ],
       "layout": "IPY_MODEL_6172c7efddca44e19859a7aa9a6c0109",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
