
# """
# üöÄ **Pseudocode for Full Data Preparation Pipeline

# (HANOI-WORLD Tier-2 Trajectory Processing)**

# ‚∏ª

# 1. Load all metadata files (multi-threaded)

# function LOAD_ALL_METADATA(metadata_dir):
#     file_list ‚Üê list all metadata_*.json in metadata_dir

#     parallel for each file in file_list:
#         js ‚Üê load JSON file into memory

#     return list of js


# ‚∏ª

# 2. Group frames by scene_token

# function GROUP_BY_SCENE(json_list):
#     scenes ‚Üê empty map: scene_token ‚Üí map(sample_token ‚Üí js)

#     for each js in json_list:
#         scene_token ‚Üê js.sample_info.scene_token
#         sample_token ‚Üê js.sample_info.sample_token
#         scenes[scene_token][sample_token] ‚Üê js

#     return scenes


# ‚∏ª

# **3. Reconstruct chronological order inside each scene

# (using prev_sample_token ‚Üí next_sample_token chain)**

# function RECONSTRUCT_SCENE(token_map):
#     # token_map: sample_token ‚Üí js

#     # Find start frame: prev_sample_token == ""
#     start ‚Üê token t where token_map[t].navigation.prev_sample_token == ""

#     ordered ‚Üê empty list
#     tok ‚Üê start

#     while tok != "":
#         ordered.append(token_map[tok])
#         tok ‚Üê token_map[tok].navigation.next_sample_token

#     return ordered


# ‚∏ª

# 4. Build complete scene_map (parallel)

# function BUILD_SCENE_MAP(metadata_dir):
#     json_list ‚Üê LOAD_ALL_METADATA(metadata_dir)
#     scenes ‚Üê GROUP_BY_SCENE(json_list)

#     parallel for each (scene_token, token_map) in scenes:
#         ordered_frames ‚Üê RECONSTRUCT_SCENE(token_map)

#         scene_map[scene_token] ‚Üê ordered_frames

#     return scene_map

# Now you have:

# scene_map = {
#     scene1: [js0, js1, js2, ..., jsN],
#     scene2: [...],
#     ...
# }


# ‚∏ª

# 5. Extract a single frame from js

# function EXTRACT_FRAME(js):
#     pos_list ‚Üê js.trajectory_window.positions
#     if pos_list empty: return None
#     return pos_list[0]


# ‚∏ª

# 6. Build backward trajectory window f(t), f(t-1), ‚Ä¶ f(t-k)

# function BUILD_BACKWARD_WINDOW(scene_seq, t, NUM_FRAMES):
#     window ‚Üê empty list

#     frame0 ‚Üê EXTRACT_FRAME(scene_seq[t])
#     zero_frame ‚Üê zero vector with same keys as frame0

#     for k in range(NUM_FRAMES):
#         idx ‚Üê t - k

#         if idx < 0:
#             window.append(zero_frame)
#         else:
#             fr ‚Üê EXTRACT_FRAME(scene_seq[idx])
#             if fr is None:
#                 window.append(zero_frame)
#             else:
#                 window.append(fr)

#     return window   # length = NUM_FRAMES


# ‚∏ª

# 7. Compute motion deltas safely (dx, dy, dv, dyaw, ds_forward, ds_side)

# function COMPUTE_WINDOWS_SAFE(frames):
#     deltas ‚Üê empty list

#     for i in range(0, len(frames)-1):
#         f0 ‚Üê frames[i]     # later frame (t)
#         f1 ‚Üê frames[i+1]   # earlier frame (t-1)

#         if f0 invalid or f1 invalid:
#             deltas.append([0,0,0,0,0,0])
#             continue

#         # --- Safe timestamp ---
#         dt ‚Üê |t0 - t1| / 1e6
#         if dt < 1e-5: dt = 1e-3
#         if dt > 0.5:  dt = 0.5

#         # --- World displacements ---
#         dx ‚Üê f0.x - f1.x
#         dy ‚Üê f0.y - f1.y

#         # large jump filtering
#         if |dx| > 50 or |dy| > 50:
#             dx = dy = 0

#         # --- Speed (from displacement) ---
#         v0 ‚Üê sqrt(dx¬≤ + dy¬≤) / dt

#         # next speed for dv
#         if i < len(frames)-2:
#             f2 ‚Üê frames[i+2]
#             compute v1 similarly (safe dt)
#         else:
#             v1 ‚Üê v0

#         dv ‚Üê v0 - v1

#         # --- Yaw difference ---
#         dyaw ‚Üê atan2(sin(yaw0 - yaw1), cos(yaw0 - yaw1))
#         if |dyaw| > 0.8: dyaw = 0

#         # --- Ego-frame displacements ---
#         cy ‚Üê cos(yaw1)
#         sy ‚Üê sin(yaw1)

#         ds_forward ‚Üê cy*dx + sy*dy
#         ds_side    ‚Üê -sy*dx + cy*dy

#         deltas.append([dx,dy,dv,dyaw,ds_forward,ds_side])

#     return deltas   # length = NUM_FRAMES-1


# ‚∏ª

# 8. Pad deltas to a fixed length (usually 8√ó6)

# function PAD_DELTAS(deltas, TARGET, DIM):
#     if len(deltas) < TARGET:
#         append zero rows until length == TARGET
#     return deltas


# ‚∏ª

# 9. Tier2Dataset Construction Using scene_map

# class Tier2Dataset:

#     init(scene_map, dataset_path, num_frames=9):
#         self.scene_map = scene_map
#         self.num_frames = num_frames

#         # build master index for global dataset
#         master_index ‚Üê []
#         for each (scene_token, frame_list) in scene_map:
#             for i in range(len(frame_list)):
#                 master_index.append((scene_token, i))

#     getitem(idx):
#         (scene_token, t) ‚Üê master_index[idx]
#         seq ‚Üê scene_map[scene_token]

#         js_current ‚Üê seq[t]

#         # 1. build backward window
#         raw_frames ‚Üê BUILD_BACKWARD_WINDOW(seq, t, num_frames)

#         # 2. compute deltas
#         deltas ‚Üê COMPUTE_WINDOWS_SAFE(raw_frames)

#         # 3. pad deltas to fixed shape
#         deltas ‚Üê PAD_DELTAS(deltas, TARGET=num_frames-1, DIM=6)

#         # 4. load local graph for current frame
#         path ‚Üê js_current.local_graph.pickle_file
#         local_graph ‚Üê load_gpickle(dataset_path/path)

#         return (local_graph, deltas, js_current)


# ‚∏ª

# 10. Dataset Normalization (optional step before training)

# function COMPUTE_GLOBAL_STATS(loader):
#     mean_acc ‚Üê zeros(6)
#     std_acc  ‚Üê zeros(6)
#     count ‚Üê 0

#     for each batch in loader:
#         x ‚Üê batch["deltas"]   # shape [B, T, 6]
#         flatten to [n, 6]

#         update running mean/std using Welford‚Äôs online update

#     return mean, std


# ‚∏ª

# üéâ Summary of the entire data flow

# metadata files ‚Üí parallel loading
#           ‚Üì
# group by scene_token
#           ‚Üì
# scene reconstruction (prev ‚Üí next)
#           ‚Üì
# scene_map[scene] = ordered js list
#           ‚Üì
# Dataset:
#     for each frame t in a scene:
#         - build backward window
#         - safe delta computation
#         - pad to fixed [8 √ó 6]
#         - load local-graph
#           ‚Üì
# DataLoader ‚Üí Tier2Model ‚Üí JEPA system


# """

# # ----------------------------------------------------------
# # 1. Load raw trajectory deltas  (from Dataset __getitem__)
# # ----------------------------------------------------------
# deltas = compute_windows_safe(raw_frames)      # [8, 6]
# deltas = pad_traj(deltas)                      # [8, 6]
# deltas = torch.tensor(deltas, float)

# # ----------------------------------------------------------
# # 2. Maybe create an augmented version of the same deltas
# # ----------------------------------------------------------

# if augment_enabled:           # dataset.augment = True
#     deltas_aug = apply_safe_augmentations(deltas)
# else:
#     deltas_aug = None

# # final Dataset output:
# return (local_graph, deltas, js_current, deltas_aug)

# def apply_safe_augmentations(d):
#     # 50% chance: use original sample
#     if random() < 0.5:
#         return d

#     # Always add small noise
#     d = d + sigma * randn_like(d)

#     # 70% chance: small rotation in BEV
#     if random() < 0.7:
#         d = rotate(d, max_deg=10)

#     # 40% chance: time-scaling of displacements
#     if random() < 0.4:
#         d = scale_time(d, 0.95, 1.05)

#     # 30% chance: randomly mask some temporal positions
#     if random() < 0.3:
#         d = temporal_mask(d, mask_prob=0.1)

#     # 25% chance: add sinusoidal lateral drift
#     if random() < 0.25:
#         d = lateral_drift(d, amp=0.1)

#     return d

# traj_raw = batch["deltas"].to(device)
