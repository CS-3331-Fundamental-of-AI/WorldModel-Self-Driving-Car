# HANOI-WORLD â€” Observation Module Prototype
### CS-3331 World-Model Autonomous Vehicle Project

This repository contains the **baseline multimodal Observation Module** for the HANOI-WORLD world-model architecture.  
It processes **image, text, trajectory, graph, and action inputs** and encodes them into unified latent representations for generative simulation and controller training.

The prototype is designed for:

âœ… Testing each encoder individually  
âœ… Visualizing multimodal latent structures  
âœ… Preparing for JEPA-style predictive world models  
âœ… Building a solid foundation for the full HANOI-WORLD system  

---

## ğŸ“ Folder Structure

CS-3331-WorldModel-AV/
â”‚
â”œâ”€â”€ observation_module/ # Main code for encoders + observe.py tool
â”‚ â”œâ”€â”€ image_encoder.py # CNN + CLIP-style projection
â”‚ â”œâ”€â”€ text_encoder.py # Token encoder + Transformer
â”‚ â”œâ”€â”€ action_encoder.py # MLP encoder
â”‚ â”œâ”€â”€ graph_encoder.py # Lightweight GCN + Transformer
â”‚ â”œâ”€â”€ trajectory_encoder.py # CNN + Transformer temporal encoder
â”‚ â”œâ”€â”€ observe.py # Multimodal inference & visualization tool
â”‚
â”œâ”€â”€ data/ # Sample multimodal input data
â”‚ â”œâ”€â”€ sample_img.jpg
â”‚ â”œâ”€â”€ sample_graph.json
â”‚ â”œâ”€â”€ sample_traj.csv
â”‚
â”œâ”€â”€ outputs/ # Auto-generated latent results + visualizations
â”‚ â”œâ”€â”€ (empty by default)
â”‚
â”œâ”€â”€ run_demo.py # Minimal encoder test using dummy data
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md


---

## ğŸ› ï¸ Installation & Setup

### âœ… 1. Clone the repository
```bash
git clone https://github.com/DTJ-Tran/CS-3331-WorldModel-AV.git
cd CS-3331-WorldModel-AV

âœ… 2. Create and activate a virtual environment
Windows
python -m venv venv
.\venv\Scripts\activate


Mac/Linux
python3 -m venv venv
source venv/bin/activate


âœ… 3. Install dependencies
pip install -r requirements.txt

ğŸš€ Running the Demo (run_demo.py)
This demo runs all encoders using dummy random data to verify that the module works.

âœ… One-line command:
python observation_module/run_demo.py

âœ… Expected Image Output
![Demo Output](demo.png)


âœ… Expected Console Output
Image latent: torch.Size([1, 256])
Text latent: torch.Size([1, 256])
Actions latent: torch.Size([1, 128])
Graph latent: torch.Size([1, 256])
Trajectory latent: torch.Size([1, 256])
Demo completed successfully!
No visualization is produced in demo mode.

ğŸ” Running the Full Observation Tool (observe.py)
Processes real multimodal data and generates 6 visualization files + latent dump.

âœ… One-line command:
python observation_module/observe.py --image data/sample_img.jpg --text "turn left at the intersection" --graph data/sample_graph.json --traj data/sample_traj.csv --actions "0.1,0.3,0.0" --save_vis --output observe_output.pkl

âœ… Expected Outputs (generated in /outputs/)
outputs/
â”‚
â”œâ”€â”€ image_vis.png
â”œâ”€â”€ graph_embedding_vis.png
â”œâ”€â”€ trajectory_vis.png
â”œâ”€â”€ latent_similarity_heatmap.png
â”œâ”€â”€ latent_distribution.png
â””â”€â”€ multimodal_dashboard.png

Also saved:
observe_output.pkl â€” all latent vectors

âœ… Example Console Output
Image processed: torch.Size([1, 256])
Text processed: torch.Size([1, 256])
Actions processed: torch.Size([1, 128])
Graph processed: torch.Size([1, 256])
Trajectory processed: torch.Size([1, 256])

âœ… Latents saved to: outputs/observe_output.pkl
âœ… Saved: outputs/image_vis.png
âœ… Saved: outputs/graph_embedding_vis.png
âœ… Saved: outputs/trajectory_vis.png
âœ… Saved: outputs/latent_similarity_heatmap.png
âœ… Saved: outputs/latent_distribution.png
âœ… Saved: outputs/multimodal_dashboard.png


âœ… Using Your Own Data
Replace paths as needed:
python observation_module/observe.py --image my_img.jpg --text "go straight" --graph hanoi_map.json --traj motorbike_traj.csv --actions "0.0,1.0,0.0" --save_vis --output my_latents.pkl

Input Format Requirements
âœ… Image
.jpg or .png
Any resolution

âœ… Graph JSON
{
  "nodes": [[x,y,z], ...],
  "adj": [[0,1,0...], ...]
}

âœ… Trajectory CSV
x,y

âœ… Actions
Comma-separated floats:
"steering, throttle, brake"

âœ… .gitignore (recommended)
venv/
__pycache__/
**/__pycache__/
outputs/
*.pkl
*.png
*.pt
*.pth
.DS_Store